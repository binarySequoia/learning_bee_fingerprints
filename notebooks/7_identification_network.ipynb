{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from keras.models import Model, Sequential \n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Conv2D, MaxPooling2D, Merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.core import Lambda\n",
    "import keras\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "CSV_DIR = '../data/csv/'\n",
    "WEIGHTS_DIR = '../weights/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_id.csv\")\n",
    "test_df = pd.read_csv(\"test_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_paths = list(train_df.X_train)\n",
    "X_test_paths = list(test_df.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(io.imread_collection(X_train_paths))\n",
    "X_test = np.array(io.imread_collection(X_test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 230, 105, 3), (200, 230, 105, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(train_df.y)\n",
    "y_test = np.array(test_df.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), (200,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 10), (200, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def base_network(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 11, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(3, 2))\n",
    "\n",
    "    model.add(Conv2D(64, 9, activation='relu', padding='VALID'))\n",
    "    model.add(Conv2D(64, 9, activation='relu', padding='VALID'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(128, 7, strides=(2,2), activation='relu', padding='SAME'))\n",
    "    model.add(Conv2D(128, 5, activation='relu', padding='VALID'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = base_network([230, 105, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=[230, 105, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_network = network(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_model = Model(input_layer, pretrained_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 230, 105, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 64)                35171392  \n",
      "=================================================================\n",
      "Total params: 35,171,392\n",
      "Trainable params: 35,171,008\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.load_weights('weights/exp_5-w.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x7f3100745908>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f310063d6a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f310076c898>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f310076c860>,\n",
       " <keras.layers.core.Dropout at 0x7f31007455c0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f30f18d38d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f30f18d9160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f30f06f4e48>,\n",
       " <keras.layers.core.Dropout at 0x7f30f058b9e8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f30f066a898>,\n",
       " <keras.layers.core.Flatten at 0x7f30f06780b8>,\n",
       " <keras.layers.core.Dense at 0x7f30f0662d30>,\n",
       " <keras.layers.core.Dropout at 0x7f30f0538d30>,\n",
       " <keras.layers.core.Dense at 0x7f30f07131d0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.layers[1].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in pretrained_model.layers[1].layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_model.layers[1].layers[-1].trainable = True\n",
    "pretrained_model.layers[1].layers[-2].trainable = True\n",
    "pretrained_model.layers[1].layers[-3].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False <keras.layers.convolutional.Conv2D object at 0x7f3100745908>\n",
      "False <keras.layers.pooling.MaxPooling2D object at 0x7f310063d6a0>\n",
      "False <keras.layers.convolutional.Conv2D object at 0x7f310076c898>\n",
      "False <keras.layers.convolutional.Conv2D object at 0x7f310076c860>\n",
      "False <keras.layers.core.Dropout object at 0x7f31007455c0>\n",
      "False <keras.layers.normalization.BatchNormalization object at 0x7f30f18d38d0>\n",
      "False <keras.layers.convolutional.Conv2D object at 0x7f30f18d9160>\n",
      "False <keras.layers.convolutional.Conv2D object at 0x7f30f06f4e48>\n",
      "False <keras.layers.core.Dropout object at 0x7f30f058b9e8>\n",
      "False <keras.layers.normalization.BatchNormalization object at 0x7f30f066a898>\n",
      "False <keras.layers.core.Flatten object at 0x7f30f06780b8>\n",
      "False <keras.layers.core.Dense object at 0x7f30f0662d30>\n",
      "True <keras.layers.core.Dropout object at 0x7f30f0538d30>\n",
      "True <keras.layers.core.Dense object at 0x7f30f07131d0>\n"
     ]
    }
   ],
   "source": [
    "for layer in network.layers:\n",
    "    print(layer.trainable, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 230, 105, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 64)                35171392  \n",
      "=================================================================\n",
      "Total params: 35,171,392\n",
      "Trainable params: 32,832\n",
      "Non-trainable params: 35,138,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "head_layer = Dropout(0.5)(pretrained_model.outputs[0]) \n",
    "head_layer = Dense(64, activation='relu')(head_layer) \n",
    "head_layer = Dense(10, activation='softmax')(head_layer)\n",
    "id_model = Model(pretrained_model.inputs, head_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 230, 105, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 64)                35171392  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 35,176,202\n",
      "Trainable params: 37,642\n",
      "Non-trainable params: 35,138,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "id_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_board = TensorBoard('logs/id_exp_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 200 samples\n",
      "Epoch 1/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.4432 - acc: 0.0550 - val_loss: 2.2931 - val_acc: 0.1450\n",
      "Epoch 2/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.2892 - acc: 0.1050 - val_loss: 2.2585 - val_acc: 0.1800\n",
      "Epoch 3/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.2687 - acc: 0.1300 - val_loss: 2.1927 - val_acc: 0.2000\n",
      "Epoch 4/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.1915 - acc: 0.1300 - val_loss: 2.1320 - val_acc: 0.2050\n",
      "Epoch 5/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.1711 - acc: 0.1850 - val_loss: 2.0414 - val_acc: 0.1450\n",
      "Epoch 6/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.0880 - acc: 0.1800 - val_loss: 2.0424 - val_acc: 0.2100\n",
      "Epoch 7/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.1377 - acc: 0.1950 - val_loss: 2.0113 - val_acc: 0.1950\n",
      "Epoch 8/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0904 - acc: 0.1600 - val_loss: 2.0118 - val_acc: 0.2200\n",
      "Epoch 9/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.0388 - acc: 0.2100 - val_loss: 1.9549 - val_acc: 0.2300\n",
      "Epoch 10/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.0477 - acc: 0.2050 - val_loss: 1.9460 - val_acc: 0.2300\n",
      "Epoch 11/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0653 - acc: 0.1850 - val_loss: 1.9455 - val_acc: 0.2350\n",
      "Epoch 12/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0590 - acc: 0.1950 - val_loss: 1.8934 - val_acc: 0.2850\n",
      "Epoch 13/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 2.0189 - acc: 0.1950 - val_loss: 1.8874 - val_acc: 0.2800\n",
      "Epoch 14/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.0332 - acc: 0.2050 - val_loss: 1.8717 - val_acc: 0.3150\n",
      "Epoch 15/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.0647 - acc: 0.1750 - val_loss: 1.8858 - val_acc: 0.2800\n",
      "Epoch 16/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.0384 - acc: 0.1450 - val_loss: 1.9270 - val_acc: 0.2500\n",
      "Epoch 17/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.9745 - acc: 0.1950 - val_loss: 1.8391 - val_acc: 0.2850\n",
      "Epoch 18/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0133 - acc: 0.1800 - val_loss: 1.8789 - val_acc: 0.3450\n",
      "Epoch 19/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 2.0063 - acc: 0.2150 - val_loss: 1.8244 - val_acc: 0.3350\n",
      "Epoch 20/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.9589 - acc: 0.1950 - val_loss: 1.7960 - val_acc: 0.2300\n",
      "Epoch 21/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0146 - acc: 0.1950 - val_loss: 1.7860 - val_acc: 0.2800\n",
      "Epoch 22/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0302 - acc: 0.1850 - val_loss: 1.8233 - val_acc: 0.3550\n",
      "Epoch 23/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.9201 - acc: 0.2300 - val_loss: 1.7647 - val_acc: 0.2900\n",
      "Epoch 24/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.9834 - acc: 0.1950 - val_loss: 1.8105 - val_acc: 0.3350\n",
      "Epoch 25/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.9910 - acc: 0.1850 - val_loss: 1.7481 - val_acc: 0.3050\n",
      "Epoch 26/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.9852 - acc: 0.2200 - val_loss: 1.7398 - val_acc: 0.3400\n",
      "Epoch 27/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.9732 - acc: 0.2000 - val_loss: 1.7102 - val_acc: 0.4100\n",
      "Epoch 28/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.9859 - acc: 0.2200 - val_loss: 1.8114 - val_acc: 0.3800\n",
      "Epoch 29/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.9038 - acc: 0.2150 - val_loss: 1.7326 - val_acc: 0.4000\n",
      "Epoch 30/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.9250 - acc: 0.2450 - val_loss: 1.7039 - val_acc: 0.4250\n",
      "Epoch 31/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.9934 - acc: 0.2050 - val_loss: 1.7674 - val_acc: 0.2950\n",
      "Epoch 32/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.8808 - acc: 0.2500 - val_loss: 1.7877 - val_acc: 0.3250\n",
      "Epoch 33/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8849 - acc: 0.2500 - val_loss: 1.7600 - val_acc: 0.2900\n",
      "Epoch 34/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8524 - acc: 0.2750 - val_loss: 1.7015 - val_acc: 0.4000\n",
      "Epoch 35/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.8565 - acc: 0.2650 - val_loss: 1.7017 - val_acc: 0.2900\n",
      "Epoch 36/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.8970 - acc: 0.2550 - val_loss: 1.7571 - val_acc: 0.2950\n",
      "Epoch 37/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.8830 - acc: 0.2500 - val_loss: 1.6821 - val_acc: 0.3400\n",
      "Epoch 38/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8472 - acc: 0.2400 - val_loss: 1.7542 - val_acc: 0.3100\n",
      "Epoch 39/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8526 - acc: 0.2500 - val_loss: 1.6877 - val_acc: 0.2750\n",
      "Epoch 40/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8682 - acc: 0.3000 - val_loss: 1.6258 - val_acc: 0.5400\n",
      "Epoch 41/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.8024 - acc: 0.2550 - val_loss: 1.7292 - val_acc: 0.3500\n",
      "Epoch 42/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.8407 - acc: 0.2500 - val_loss: 1.6193 - val_acc: 0.4250\n",
      "Epoch 43/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8172 - acc: 0.2600 - val_loss: 1.6416 - val_acc: 0.3300\n",
      "Epoch 44/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.8075 - acc: 0.2500 - val_loss: 1.7411 - val_acc: 0.2800\n",
      "Epoch 45/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7522 - acc: 0.2700 - val_loss: 1.6221 - val_acc: 0.4300\n",
      "Epoch 46/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7372 - acc: 0.3000 - val_loss: 1.6421 - val_acc: 0.4350\n",
      "Epoch 47/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8524 - acc: 0.2450 - val_loss: 1.6921 - val_acc: 0.2500\n",
      "Epoch 48/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7541 - acc: 0.2750 - val_loss: 1.6530 - val_acc: 0.4200\n",
      "Epoch 49/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8706 - acc: 0.2400 - val_loss: 1.7239 - val_acc: 0.3400\n",
      "Epoch 50/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8037 - acc: 0.2500 - val_loss: 1.5861 - val_acc: 0.3700\n",
      "Epoch 51/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8117 - acc: 0.2450 - val_loss: 1.7120 - val_acc: 0.2950\n",
      "Epoch 52/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7728 - acc: 0.3000 - val_loss: 1.6631 - val_acc: 0.3750\n",
      "Epoch 53/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.8203 - acc: 0.2200 - val_loss: 1.6789 - val_acc: 0.3400\n",
      "Epoch 54/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.7548 - acc: 0.2650 - val_loss: 1.6312 - val_acc: 0.3500\n",
      "Epoch 55/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8028 - acc: 0.2750 - val_loss: 1.5947 - val_acc: 0.3750\n",
      "Epoch 56/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7994 - acc: 0.3100 - val_loss: 1.6579 - val_acc: 0.3250\n",
      "Epoch 57/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8602 - acc: 0.2350 - val_loss: 1.6583 - val_acc: 0.3500\n",
      "Epoch 58/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7106 - acc: 0.2700 - val_loss: 1.6697 - val_acc: 0.3300\n",
      "Epoch 59/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7099 - acc: 0.2900 - val_loss: 1.6329 - val_acc: 0.4050\n",
      "Epoch 60/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7925 - acc: 0.2800 - val_loss: 1.6278 - val_acc: 0.3650\n",
      "Epoch 61/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.7443 - acc: 0.2950 - val_loss: 1.5353 - val_acc: 0.4300\n",
      "Epoch 62/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8211 - acc: 0.2650 - val_loss: 1.6542 - val_acc: 0.3100\n",
      "Epoch 63/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7908 - acc: 0.2700 - val_loss: 1.5888 - val_acc: 0.4550\n",
      "Epoch 64/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.8583 - acc: 0.2600 - val_loss: 1.5950 - val_acc: 0.4600\n",
      "Epoch 65/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6524 - acc: 0.3250 - val_loss: 1.5408 - val_acc: 0.4500\n",
      "Epoch 66/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7924 - acc: 0.3050 - val_loss: 1.6137 - val_acc: 0.4000\n",
      "Epoch 67/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7453 - acc: 0.3100 - val_loss: 1.6199 - val_acc: 0.3450\n",
      "Epoch 68/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7187 - acc: 0.3000 - val_loss: 1.6197 - val_acc: 0.4500\n",
      "Epoch 69/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7865 - acc: 0.2850 - val_loss: 1.6741 - val_acc: 0.3800\n",
      "Epoch 70/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7970 - acc: 0.2950 - val_loss: 1.6334 - val_acc: 0.3800\n",
      "Epoch 71/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.7797 - acc: 0.2850 - val_loss: 1.5699 - val_acc: 0.4950\n",
      "Epoch 72/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8270 - acc: 0.2750 - val_loss: 1.6512 - val_acc: 0.3600\n",
      "Epoch 73/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7761 - acc: 0.2750 - val_loss: 1.6609 - val_acc: 0.3500\n",
      "Epoch 74/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6774 - acc: 0.3150 - val_loss: 1.5992 - val_acc: 0.3950\n",
      "Epoch 75/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7940 - acc: 0.2650 - val_loss: 1.6062 - val_acc: 0.3500\n",
      "Epoch 76/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7783 - acc: 0.2850 - val_loss: 1.6339 - val_acc: 0.4550\n",
      "Epoch 77/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7401 - acc: 0.3250 - val_loss: 1.7095 - val_acc: 0.3950\n",
      "Epoch 78/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.6583 - acc: 0.2900 - val_loss: 1.6696 - val_acc: 0.4100\n",
      "Epoch 79/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6405 - acc: 0.3200 - val_loss: 1.7119 - val_acc: 0.4100\n",
      "Epoch 80/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7129 - acc: 0.3350 - val_loss: 1.7937 - val_acc: 0.3150\n",
      "Epoch 81/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.7327 - acc: 0.2650 - val_loss: 1.6230 - val_acc: 0.4950\n",
      "Epoch 82/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7045 - acc: 0.3250 - val_loss: 1.6886 - val_acc: 0.3800\n",
      "Epoch 83/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7412 - acc: 0.2800 - val_loss: 1.6540 - val_acc: 0.4050\n",
      "Epoch 84/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6334 - acc: 0.3450 - val_loss: 1.7319 - val_acc: 0.3450\n",
      "Epoch 85/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.7120 - acc: 0.3350 - val_loss: 1.7478 - val_acc: 0.3050\n",
      "Epoch 86/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7436 - acc: 0.3050 - val_loss: 1.6952 - val_acc: 0.3550\n",
      "Epoch 87/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6603 - acc: 0.3200 - val_loss: 1.6571 - val_acc: 0.4650\n",
      "Epoch 88/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6630 - acc: 0.3450 - val_loss: 1.7633 - val_acc: 0.2700\n",
      "Epoch 89/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.6001 - acc: 0.3450 - val_loss: 1.6871 - val_acc: 0.3950\n",
      "Epoch 90/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6654 - acc: 0.3350 - val_loss: 1.7254 - val_acc: 0.3700\n",
      "Epoch 91/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6385 - acc: 0.3500 - val_loss: 1.6822 - val_acc: 0.3750\n",
      "Epoch 92/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6413 - acc: 0.3800 - val_loss: 1.6738 - val_acc: 0.3800\n",
      "Epoch 93/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6825 - acc: 0.3450 - val_loss: 1.7246 - val_acc: 0.3000\n",
      "Epoch 94/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6882 - acc: 0.3100 - val_loss: 1.7429 - val_acc: 0.3750\n",
      "Epoch 95/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7311 - acc: 0.3100 - val_loss: 1.6368 - val_acc: 0.3650\n",
      "Epoch 96/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5430 - acc: 0.3550 - val_loss: 1.6155 - val_acc: 0.4000\n",
      "Epoch 97/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5938 - acc: 0.3400 - val_loss: 1.6730 - val_acc: 0.4400\n",
      "Epoch 98/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7344 - acc: 0.3250 - val_loss: 1.6737 - val_acc: 0.4200\n",
      "Epoch 99/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6544 - acc: 0.3300 - val_loss: 1.6533 - val_acc: 0.4150\n",
      "Epoch 100/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6420 - acc: 0.3350 - val_loss: 1.7401 - val_acc: 0.3800\n",
      "Epoch 101/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.6311 - acc: 0.3500 - val_loss: 1.5986 - val_acc: 0.5250\n",
      "Epoch 102/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6167 - acc: 0.3500 - val_loss: 1.6187 - val_acc: 0.4600\n",
      "Epoch 103/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6750 - acc: 0.3050 - val_loss: 1.6027 - val_acc: 0.5400\n",
      "Epoch 104/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5886 - acc: 0.3500 - val_loss: 1.7509 - val_acc: 0.2900\n",
      "Epoch 105/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.5549 - acc: 0.3650 - val_loss: 1.8104 - val_acc: 0.2850\n",
      "Epoch 106/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6201 - acc: 0.3850 - val_loss: 1.5823 - val_acc: 0.4400\n",
      "Epoch 107/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.7022 - acc: 0.3550 - val_loss: 1.6351 - val_acc: 0.4100\n",
      "Epoch 108/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.5694 - acc: 0.3400 - val_loss: 1.5741 - val_acc: 0.4400\n",
      "Epoch 109/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4631 - acc: 0.3850 - val_loss: 1.5524 - val_acc: 0.4800\n",
      "Epoch 110/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6774 - acc: 0.3200 - val_loss: 1.6740 - val_acc: 0.3400\n",
      "Epoch 111/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5409 - acc: 0.3900 - val_loss: 1.4588 - val_acc: 0.4950\n",
      "Epoch 112/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.5818 - acc: 0.3400 - val_loss: 1.5571 - val_acc: 0.4850\n",
      "Epoch 113/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5242 - acc: 0.4000 - val_loss: 1.6221 - val_acc: 0.4800\n",
      "Epoch 114/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4679 - acc: 0.3650 - val_loss: 1.5820 - val_acc: 0.4550\n",
      "Epoch 115/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3500 - acc: 0.4100 - val_loss: 1.6039 - val_acc: 0.4200\n",
      "Epoch 116/1000\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 1.5109 - acc: 0.3800 - val_loss: 1.5894 - val_acc: 0.4700\n",
      "Epoch 117/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4325 - acc: 0.3850 - val_loss: 1.6267 - val_acc: 0.4800\n",
      "Epoch 118/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6055 - acc: 0.3950 - val_loss: 1.6258 - val_acc: 0.4050\n",
      "Epoch 119/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4510 - acc: 0.3650 - val_loss: 1.6242 - val_acc: 0.4250\n",
      "Epoch 120/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.6098 - acc: 0.3400 - val_loss: 1.5793 - val_acc: 0.4100\n",
      "Epoch 121/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5381 - acc: 0.3450 - val_loss: 1.5884 - val_acc: 0.4450\n",
      "Epoch 122/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4942 - acc: 0.3850 - val_loss: 1.5304 - val_acc: 0.5200\n",
      "Epoch 123/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.5553 - acc: 0.3650 - val_loss: 1.6244 - val_acc: 0.3850\n",
      "Epoch 124/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.6295 - acc: 0.3750 - val_loss: 1.5667 - val_acc: 0.4450\n",
      "Epoch 125/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4235 - acc: 0.4250 - val_loss: 1.5793 - val_acc: 0.4400\n",
      "Epoch 126/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5391 - acc: 0.4100 - val_loss: 1.5537 - val_acc: 0.4950\n",
      "Epoch 127/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.5159 - acc: 0.3750 - val_loss: 1.3679 - val_acc: 0.4750\n",
      "Epoch 128/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4602 - acc: 0.3700 - val_loss: 1.4334 - val_acc: 0.4350\n",
      "Epoch 129/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4497 - acc: 0.3800 - val_loss: 1.3720 - val_acc: 0.5150\n",
      "Epoch 130/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5132 - acc: 0.3700 - val_loss: 1.4427 - val_acc: 0.4850\n",
      "Epoch 131/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.4820 - acc: 0.4000 - val_loss: 1.4835 - val_acc: 0.4400\n",
      "Epoch 132/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5003 - acc: 0.4000 - val_loss: 1.4966 - val_acc: 0.4550\n",
      "Epoch 133/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4922 - acc: 0.3600 - val_loss: 1.6873 - val_acc: 0.3050\n",
      "Epoch 134/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.4215 - acc: 0.4300 - val_loss: 1.5069 - val_acc: 0.4400\n",
      "Epoch 135/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4491 - acc: 0.3800 - val_loss: 1.4382 - val_acc: 0.5500\n",
      "Epoch 136/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4791 - acc: 0.3500 - val_loss: 1.4377 - val_acc: 0.5700\n",
      "Epoch 137/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4798 - acc: 0.3450 - val_loss: 1.4261 - val_acc: 0.5450\n",
      "Epoch 138/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.5408 - acc: 0.3550 - val_loss: 1.5400 - val_acc: 0.4250\n",
      "Epoch 139/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3822 - acc: 0.3600 - val_loss: 1.5930 - val_acc: 0.4900\n",
      "Epoch 140/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3847 - acc: 0.4150 - val_loss: 1.4897 - val_acc: 0.4450\n",
      "Epoch 141/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5291 - acc: 0.4250 - val_loss: 1.3798 - val_acc: 0.5000\n",
      "Epoch 142/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4733 - acc: 0.3750 - val_loss: 1.4328 - val_acc: 0.4700\n",
      "Epoch 143/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3864 - acc: 0.4200 - val_loss: 1.4603 - val_acc: 0.5000\n",
      "Epoch 144/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.6652 - val_acc: 0.4300\n",
      "Epoch 145/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.5158 - acc: 0.3450 - val_loss: 1.6348 - val_acc: 0.4300\n",
      "Epoch 146/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3618 - acc: 0.4200 - val_loss: 1.5893 - val_acc: 0.4350\n",
      "Epoch 147/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5646 - acc: 0.4100 - val_loss: 1.6457 - val_acc: 0.4000\n",
      "Epoch 148/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3468 - acc: 0.4000 - val_loss: 1.6219 - val_acc: 0.4400\n",
      "Epoch 149/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3173 - acc: 0.4500 - val_loss: 1.4870 - val_acc: 0.4400\n",
      "Epoch 150/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3722 - acc: 0.4350 - val_loss: 1.5323 - val_acc: 0.3650\n",
      "Epoch 151/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3943 - acc: 0.4300 - val_loss: 1.4689 - val_acc: 0.4900\n",
      "Epoch 152/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4019 - acc: 0.4550 - val_loss: 1.4342 - val_acc: 0.5100\n",
      "Epoch 153/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3692 - acc: 0.4150 - val_loss: 1.4727 - val_acc: 0.4600\n",
      "Epoch 154/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5052 - acc: 0.4250 - val_loss: 1.5029 - val_acc: 0.4050\n",
      "Epoch 155/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4617 - acc: 0.3950 - val_loss: 1.3950 - val_acc: 0.5500\n",
      "Epoch 156/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4097 - acc: 0.4300 - val_loss: 1.4921 - val_acc: 0.3950\n",
      "Epoch 157/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2770 - acc: 0.4900 - val_loss: 1.5051 - val_acc: 0.4600\n",
      "Epoch 158/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4020 - acc: 0.4150 - val_loss: 1.5252 - val_acc: 0.4200\n",
      "Epoch 159/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4464 - acc: 0.4050 - val_loss: 1.4203 - val_acc: 0.5050\n",
      "Epoch 160/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3288 - acc: 0.4600 - val_loss: 1.4506 - val_acc: 0.4600\n",
      "Epoch 161/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3845 - acc: 0.4500 - val_loss: 1.4328 - val_acc: 0.5100\n",
      "Epoch 162/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3754 - acc: 0.4450 - val_loss: 1.7380 - val_acc: 0.3650\n",
      "Epoch 163/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.5353 - acc: 0.4000 - val_loss: 1.5692 - val_acc: 0.3950\n",
      "Epoch 164/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3601 - acc: 0.4100 - val_loss: 1.4949 - val_acc: 0.4400\n",
      "Epoch 165/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3111 - acc: 0.4250 - val_loss: 1.4486 - val_acc: 0.4650\n",
      "Epoch 166/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3759 - acc: 0.4500 - val_loss: 1.6452 - val_acc: 0.3600\n",
      "Epoch 167/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4125 - acc: 0.4150 - val_loss: 1.4763 - val_acc: 0.4900\n",
      "Epoch 168/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3831 - acc: 0.4050 - val_loss: 1.4309 - val_acc: 0.4900\n",
      "Epoch 169/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4288 - acc: 0.4200 - val_loss: 1.4453 - val_acc: 0.4450\n",
      "Epoch 170/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3718 - acc: 0.4450 - val_loss: 1.4118 - val_acc: 0.4950\n",
      "Epoch 171/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3921 - acc: 0.4000 - val_loss: 1.4419 - val_acc: 0.4650\n",
      "Epoch 172/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3261 - acc: 0.4600 - val_loss: 1.6071 - val_acc: 0.2800\n",
      "Epoch 173/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3168 - acc: 0.4600 - val_loss: 1.4800 - val_acc: 0.4550\n",
      "Epoch 174/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2669 - acc: 0.4650 - val_loss: 1.5741 - val_acc: 0.3850\n",
      "Epoch 175/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2545 - acc: 0.4800 - val_loss: 1.5249 - val_acc: 0.4900\n",
      "Epoch 176/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3820 - acc: 0.4250 - val_loss: 1.5269 - val_acc: 0.4950\n",
      "Epoch 177/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4608 - acc: 0.4150 - val_loss: 1.5335 - val_acc: 0.4650\n",
      "Epoch 178/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2986 - acc: 0.4800 - val_loss: 1.4446 - val_acc: 0.4700\n",
      "Epoch 179/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2631 - acc: 0.4700 - val_loss: 1.4490 - val_acc: 0.4350\n",
      "Epoch 180/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2651 - acc: 0.4550 - val_loss: 1.4653 - val_acc: 0.4450\n",
      "Epoch 181/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3295 - acc: 0.4550 - val_loss: 1.4035 - val_acc: 0.5350\n",
      "Epoch 182/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2776 - acc: 0.4700 - val_loss: 1.4344 - val_acc: 0.4800\n",
      "Epoch 183/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2223 - acc: 0.4250 - val_loss: 1.5740 - val_acc: 0.4000\n",
      "Epoch 184/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2649 - acc: 0.4700 - val_loss: 1.5675 - val_acc: 0.3800\n",
      "Epoch 185/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3581 - acc: 0.4250 - val_loss: 1.5176 - val_acc: 0.4200\n",
      "Epoch 186/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2621 - acc: 0.4700 - val_loss: 1.6565 - val_acc: 0.3900\n",
      "Epoch 187/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3344 - acc: 0.4150 - val_loss: 1.4565 - val_acc: 0.5100\n",
      "Epoch 188/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4319 - acc: 0.4350 - val_loss: 1.5261 - val_acc: 0.3850\n",
      "Epoch 189/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2216 - acc: 0.4950 - val_loss: 1.5203 - val_acc: 0.3950\n",
      "Epoch 190/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3166 - acc: 0.4500 - val_loss: 1.5154 - val_acc: 0.4500\n",
      "Epoch 191/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2348 - acc: 0.4750 - val_loss: 1.4802 - val_acc: 0.4650\n",
      "Epoch 192/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2644 - acc: 0.5100 - val_loss: 1.4010 - val_acc: 0.4550\n",
      "Epoch 193/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2653 - acc: 0.4850 - val_loss: 1.4498 - val_acc: 0.4150\n",
      "Epoch 194/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1552 - acc: 0.5250 - val_loss: 1.4018 - val_acc: 0.4550\n",
      "Epoch 195/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2255 - acc: 0.4700 - val_loss: 1.6390 - val_acc: 0.3750\n",
      "Epoch 196/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2368 - acc: 0.4700 - val_loss: 1.5138 - val_acc: 0.4600\n",
      "Epoch 197/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.4115 - acc: 0.4300 - val_loss: 1.4964 - val_acc: 0.5150\n",
      "Epoch 198/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3005 - acc: 0.4350 - val_loss: 1.6445 - val_acc: 0.4600\n",
      "Epoch 199/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2517 - acc: 0.4550 - val_loss: 1.5422 - val_acc: 0.4650\n",
      "Epoch 200/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1716 - acc: 0.4900 - val_loss: 1.4075 - val_acc: 0.5350\n",
      "Epoch 201/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2130 - acc: 0.4750 - val_loss: 1.5017 - val_acc: 0.4300\n",
      "Epoch 202/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2577 - acc: 0.4800 - val_loss: 1.5693 - val_acc: 0.4800\n",
      "Epoch 203/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2602 - acc: 0.4500 - val_loss: 1.6019 - val_acc: 0.4800\n",
      "Epoch 204/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2381 - acc: 0.4700 - val_loss: 1.8241 - val_acc: 0.3600\n",
      "Epoch 205/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1417 - acc: 0.4700 - val_loss: 1.7631 - val_acc: 0.3900\n",
      "Epoch 206/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1923 - acc: 0.4450 - val_loss: 1.7059 - val_acc: 0.3550\n",
      "Epoch 207/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2850 - acc: 0.4650 - val_loss: 1.6802 - val_acc: 0.4250\n",
      "Epoch 208/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1363 - acc: 0.4900 - val_loss: 1.7333 - val_acc: 0.4100\n",
      "Epoch 209/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2611 - acc: 0.4650 - val_loss: 1.6065 - val_acc: 0.4700\n",
      "Epoch 210/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2393 - acc: 0.5150 - val_loss: 1.8056 - val_acc: 0.3150\n",
      "Epoch 211/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2820 - acc: 0.5000 - val_loss: 1.7165 - val_acc: 0.3850\n",
      "Epoch 212/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2981 - acc: 0.4700 - val_loss: 1.7152 - val_acc: 0.3700\n",
      "Epoch 213/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1350 - acc: 0.5000 - val_loss: 1.6079 - val_acc: 0.4250\n",
      "Epoch 214/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1705 - acc: 0.4850 - val_loss: 1.5658 - val_acc: 0.4300\n",
      "Epoch 215/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0928 - acc: 0.5450 - val_loss: 1.6871 - val_acc: 0.3500\n",
      "Epoch 216/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2137 - acc: 0.4800 - val_loss: 1.7364 - val_acc: 0.3600\n",
      "Epoch 217/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2331 - acc: 0.4250 - val_loss: 1.8201 - val_acc: 0.3250\n",
      "Epoch 218/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1431 - acc: 0.5300 - val_loss: 1.5181 - val_acc: 0.4200\n",
      "Epoch 219/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1997 - acc: 0.5000 - val_loss: 1.5322 - val_acc: 0.4800\n",
      "Epoch 220/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2605 - acc: 0.4850 - val_loss: 1.6466 - val_acc: 0.4200\n",
      "Epoch 221/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2568 - acc: 0.4350 - val_loss: 1.5168 - val_acc: 0.5200\n",
      "Epoch 222/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3298 - acc: 0.4600 - val_loss: 1.5173 - val_acc: 0.4100\n",
      "Epoch 223/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2697 - acc: 0.4850 - val_loss: 1.5435 - val_acc: 0.4000\n",
      "Epoch 224/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3507 - acc: 0.4300 - val_loss: 1.6129 - val_acc: 0.4100\n",
      "Epoch 225/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2450 - acc: 0.5000 - val_loss: 1.6808 - val_acc: 0.4800\n",
      "Epoch 226/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1773 - acc: 0.5250 - val_loss: 1.7387 - val_acc: 0.4450\n",
      "Epoch 227/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1590 - acc: 0.5200 - val_loss: 1.7062 - val_acc: 0.3850\n",
      "Epoch 228/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2360 - acc: 0.5050 - val_loss: 1.6496 - val_acc: 0.4800\n",
      "Epoch 229/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1774 - acc: 0.5150 - val_loss: 1.8236 - val_acc: 0.3750\n",
      "Epoch 230/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1821 - acc: 0.5400 - val_loss: 1.6293 - val_acc: 0.3650\n",
      "Epoch 231/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0740 - acc: 0.5650 - val_loss: 1.7019 - val_acc: 0.4050\n",
      "Epoch 232/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1722 - acc: 0.5000 - val_loss: 1.5456 - val_acc: 0.3900\n",
      "Epoch 233/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1834 - acc: 0.5150 - val_loss: 1.5648 - val_acc: 0.4500\n",
      "Epoch 234/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1194 - acc: 0.5250 - val_loss: 1.6228 - val_acc: 0.4150\n",
      "Epoch 235/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1735 - acc: 0.5450 - val_loss: 1.6295 - val_acc: 0.3850\n",
      "Epoch 236/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2255 - acc: 0.5000 - val_loss: 1.4603 - val_acc: 0.4600\n",
      "Epoch 237/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1860 - acc: 0.4900 - val_loss: 1.4741 - val_acc: 0.4600\n",
      "Epoch 238/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2173 - acc: 0.5150 - val_loss: 1.5977 - val_acc: 0.3850\n",
      "Epoch 239/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2018 - acc: 0.4900 - val_loss: 1.4921 - val_acc: 0.5700\n",
      "Epoch 240/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0667 - acc: 0.5300 - val_loss: 1.5249 - val_acc: 0.4000\n",
      "Epoch 241/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2678 - acc: 0.4650 - val_loss: 1.5856 - val_acc: 0.4000\n",
      "Epoch 242/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1344 - acc: 0.4750 - val_loss: 1.5119 - val_acc: 0.4250\n",
      "Epoch 243/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2666 - acc: 0.5300 - val_loss: 1.6508 - val_acc: 0.3900\n",
      "Epoch 244/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1781 - acc: 0.5350 - val_loss: 1.4982 - val_acc: 0.5200\n",
      "Epoch 245/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9935 - acc: 0.6050 - val_loss: 1.6368 - val_acc: 0.4500\n",
      "Epoch 246/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2385 - acc: 0.5500 - val_loss: 1.5296 - val_acc: 0.5150\n",
      "Epoch 247/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1358 - acc: 0.5500 - val_loss: 1.5119 - val_acc: 0.5350\n",
      "Epoch 248/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0731 - acc: 0.5450 - val_loss: 1.3243 - val_acc: 0.5900\n",
      "Epoch 249/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2037 - acc: 0.5200 - val_loss: 1.4467 - val_acc: 0.4950\n",
      "Epoch 250/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0611 - acc: 0.5850 - val_loss: 1.4811 - val_acc: 0.4600\n",
      "Epoch 251/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3119 - acc: 0.4900 - val_loss: 1.8164 - val_acc: 0.4750\n",
      "Epoch 252/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0715 - acc: 0.5450 - val_loss: 1.6414 - val_acc: 0.4450\n",
      "Epoch 253/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1071 - acc: 0.5700 - val_loss: 1.7856 - val_acc: 0.4550\n",
      "Epoch 254/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0661 - acc: 0.5250 - val_loss: 1.7933 - val_acc: 0.4300\n",
      "Epoch 255/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1330 - acc: 0.5200 - val_loss: 1.7011 - val_acc: 0.4300\n",
      "Epoch 256/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1314 - acc: 0.5350 - val_loss: 1.6914 - val_acc: 0.5000\n",
      "Epoch 257/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1134 - acc: 0.5050 - val_loss: 1.5794 - val_acc: 0.4500\n",
      "Epoch 258/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2067 - acc: 0.4600 - val_loss: 1.7377 - val_acc: 0.4550\n",
      "Epoch 259/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1373 - acc: 0.5550 - val_loss: 1.4664 - val_acc: 0.5750\n",
      "Epoch 260/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0842 - acc: 0.5500 - val_loss: 1.4616 - val_acc: 0.5500\n",
      "Epoch 261/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1619 - acc: 0.4950 - val_loss: 1.6244 - val_acc: 0.4200\n",
      "Epoch 262/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0746 - acc: 0.5900 - val_loss: 1.6962 - val_acc: 0.4350\n",
      "Epoch 263/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1746 - acc: 0.5400 - val_loss: 1.7218 - val_acc: 0.4650\n",
      "Epoch 264/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1536 - acc: 0.5300 - val_loss: 1.7146 - val_acc: 0.5150\n",
      "Epoch 265/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0411 - acc: 0.5750 - val_loss: 1.6236 - val_acc: 0.4900\n",
      "Epoch 266/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0255 - acc: 0.5550 - val_loss: 1.4967 - val_acc: 0.6200\n",
      "Epoch 267/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1517 - acc: 0.5250 - val_loss: 1.6100 - val_acc: 0.4550\n",
      "Epoch 268/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2077 - acc: 0.5400 - val_loss: 1.6176 - val_acc: 0.5250\n",
      "Epoch 269/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1524 - acc: 0.4950 - val_loss: 1.6052 - val_acc: 0.5650\n",
      "Epoch 270/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0406 - acc: 0.5850 - val_loss: 1.6082 - val_acc: 0.5150\n",
      "Epoch 271/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1398 - acc: 0.5300 - val_loss: 1.6222 - val_acc: 0.4700\n",
      "Epoch 272/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1784 - acc: 0.5600 - val_loss: 1.6359 - val_acc: 0.4750\n",
      "Epoch 273/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0880 - acc: 0.5600 - val_loss: 1.7159 - val_acc: 0.4800\n",
      "Epoch 274/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0102 - acc: 0.5850 - val_loss: 1.5305 - val_acc: 0.5250\n",
      "Epoch 275/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9910 - acc: 0.6000 - val_loss: 1.4468 - val_acc: 0.6000\n",
      "Epoch 276/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1147 - acc: 0.5500 - val_loss: 1.6771 - val_acc: 0.5050\n",
      "Epoch 277/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2238 - acc: 0.5450 - val_loss: 1.4491 - val_acc: 0.5650\n",
      "Epoch 278/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0431 - acc: 0.5500 - val_loss: 1.5262 - val_acc: 0.4850\n",
      "Epoch 279/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1256 - acc: 0.5450 - val_loss: 1.5409 - val_acc: 0.4900\n",
      "Epoch 280/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1678 - acc: 0.5250 - val_loss: 1.4768 - val_acc: 0.5050\n",
      "Epoch 281/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1541 - acc: 0.5400 - val_loss: 1.3740 - val_acc: 0.5550\n",
      "Epoch 282/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1281 - acc: 0.5350 - val_loss: 1.3353 - val_acc: 0.5150\n",
      "Epoch 283/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1457 - acc: 0.5400 - val_loss: 1.3357 - val_acc: 0.5950\n",
      "Epoch 284/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2064 - acc: 0.5300 - val_loss: 1.4156 - val_acc: 0.6050\n",
      "Epoch 285/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0695 - acc: 0.5600 - val_loss: 1.3070 - val_acc: 0.6500\n",
      "Epoch 286/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0210 - acc: 0.5850 - val_loss: 1.3933 - val_acc: 0.5050\n",
      "Epoch 287/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0394 - acc: 0.6100 - val_loss: 1.3704 - val_acc: 0.5900\n",
      "Epoch 288/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1392 - acc: 0.5350 - val_loss: 1.2592 - val_acc: 0.6300\n",
      "Epoch 289/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0030 - acc: 0.6100 - val_loss: 1.3846 - val_acc: 0.5450\n",
      "Epoch 290/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0718 - acc: 0.5450 - val_loss: 1.4069 - val_acc: 0.5900\n",
      "Epoch 291/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0279 - acc: 0.5650 - val_loss: 1.3312 - val_acc: 0.5550\n",
      "Epoch 292/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0547 - acc: 0.5650 - val_loss: 1.2394 - val_acc: 0.6300\n",
      "Epoch 293/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1963 - acc: 0.5300 - val_loss: 1.5573 - val_acc: 0.4800\n",
      "Epoch 294/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0616 - acc: 0.5350 - val_loss: 1.6068 - val_acc: 0.5050\n",
      "Epoch 295/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0692 - acc: 0.5700 - val_loss: 1.3850 - val_acc: 0.5150\n",
      "Epoch 296/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0828 - acc: 0.5750 - val_loss: 1.3220 - val_acc: 0.5950\n",
      "Epoch 297/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9626 - acc: 0.5900 - val_loss: 1.3510 - val_acc: 0.5750\n",
      "Epoch 298/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1616 - acc: 0.5500 - val_loss: 1.3706 - val_acc: 0.6250\n",
      "Epoch 299/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0652 - acc: 0.5850 - val_loss: 1.3676 - val_acc: 0.5900\n",
      "Epoch 300/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1347 - acc: 0.5500 - val_loss: 1.4272 - val_acc: 0.5450\n",
      "Epoch 301/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0397 - acc: 0.5900 - val_loss: 1.5763 - val_acc: 0.4900\n",
      "Epoch 302/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0822 - acc: 0.5750 - val_loss: 1.3814 - val_acc: 0.6000\n",
      "Epoch 303/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9500 - acc: 0.6200 - val_loss: 1.5614 - val_acc: 0.5000\n",
      "Epoch 304/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2358 - acc: 0.5250 - val_loss: 1.3860 - val_acc: 0.5100\n",
      "Epoch 305/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0151 - acc: 0.5850 - val_loss: 1.4512 - val_acc: 0.4750\n",
      "Epoch 306/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2154 - acc: 0.5300 - val_loss: 1.2660 - val_acc: 0.6400\n",
      "Epoch 307/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1225 - acc: 0.5300 - val_loss: 1.4629 - val_acc: 0.5350\n",
      "Epoch 308/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9003 - acc: 0.6400 - val_loss: 1.3242 - val_acc: 0.5700\n",
      "Epoch 309/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0004 - acc: 0.5500 - val_loss: 1.2359 - val_acc: 0.6350\n",
      "Epoch 310/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0405 - acc: 0.5700 - val_loss: 1.5043 - val_acc: 0.5000\n",
      "Epoch 311/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0999 - acc: 0.5550 - val_loss: 1.4330 - val_acc: 0.5050\n",
      "Epoch 312/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1226 - acc: 0.5550 - val_loss: 1.6267 - val_acc: 0.4500\n",
      "Epoch 313/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1013 - acc: 0.5650 - val_loss: 1.4019 - val_acc: 0.5050\n",
      "Epoch 314/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0697 - acc: 0.5750 - val_loss: 1.4202 - val_acc: 0.5550\n",
      "Epoch 315/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0024 - acc: 0.6150 - val_loss: 1.3875 - val_acc: 0.5200\n",
      "Epoch 316/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2860 - acc: 0.5000 - val_loss: 1.2783 - val_acc: 0.5400\n",
      "Epoch 317/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1074 - acc: 0.5550 - val_loss: 1.3851 - val_acc: 0.5050\n",
      "Epoch 318/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0338 - acc: 0.5950 - val_loss: 1.3526 - val_acc: 0.5000\n",
      "Epoch 319/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0533 - acc: 0.5600 - val_loss: 1.5262 - val_acc: 0.5050\n",
      "Epoch 320/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1471 - acc: 0.5650 - val_loss: 1.4315 - val_acc: 0.5150\n",
      "Epoch 321/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9224 - acc: 0.6350 - val_loss: 1.3733 - val_acc: 0.5050\n",
      "Epoch 322/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1594 - acc: 0.5450 - val_loss: 1.4924 - val_acc: 0.4700\n",
      "Epoch 323/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0618 - acc: 0.5400 - val_loss: 1.3570 - val_acc: 0.4800\n",
      "Epoch 324/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1630 - acc: 0.5450 - val_loss: 1.2576 - val_acc: 0.6100\n",
      "Epoch 325/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0499 - acc: 0.5800 - val_loss: 1.3247 - val_acc: 0.5500\n",
      "Epoch 326/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2823 - acc: 0.5000 - val_loss: 1.4594 - val_acc: 0.5100\n",
      "Epoch 327/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0666 - acc: 0.5400 - val_loss: 1.2566 - val_acc: 0.6150\n",
      "Epoch 328/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0323 - acc: 0.5750 - val_loss: 1.3690 - val_acc: 0.4800\n",
      "Epoch 329/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1998 - acc: 0.5400 - val_loss: 1.4213 - val_acc: 0.4900\n",
      "Epoch 330/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0218 - acc: 0.6050 - val_loss: 1.3782 - val_acc: 0.5750\n",
      "Epoch 331/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1951 - acc: 0.5200 - val_loss: 1.4822 - val_acc: 0.4600\n",
      "Epoch 332/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0944 - acc: 0.5500 - val_loss: 1.4300 - val_acc: 0.5000\n",
      "Epoch 333/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.2035 - acc: 0.5200 - val_loss: 1.3207 - val_acc: 0.5300\n",
      "Epoch 334/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0953 - acc: 0.5750 - val_loss: 1.3777 - val_acc: 0.5200\n",
      "Epoch 335/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0461 - acc: 0.5800 - val_loss: 1.3996 - val_acc: 0.4600\n",
      "Epoch 336/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0249 - acc: 0.5950 - val_loss: 1.4269 - val_acc: 0.4900\n",
      "Epoch 337/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9894 - acc: 0.6050 - val_loss: 1.5553 - val_acc: 0.4950\n",
      "Epoch 338/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1719 - acc: 0.5100 - val_loss: 1.5785 - val_acc: 0.5050\n",
      "Epoch 339/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2054 - acc: 0.5100 - val_loss: 1.4652 - val_acc: 0.5200\n",
      "Epoch 340/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1052 - acc: 0.5700 - val_loss: 1.6123 - val_acc: 0.5000\n",
      "Epoch 341/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0729 - acc: 0.5800 - val_loss: 1.4163 - val_acc: 0.5150\n",
      "Epoch 342/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0376 - acc: 0.5550 - val_loss: 1.3319 - val_acc: 0.4650\n",
      "Epoch 343/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9772 - acc: 0.6150 - val_loss: 1.5020 - val_acc: 0.4500\n",
      "Epoch 344/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9263 - acc: 0.6400 - val_loss: 1.4394 - val_acc: 0.4850\n",
      "Epoch 345/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0616 - acc: 0.6100 - val_loss: 1.3242 - val_acc: 0.5250\n",
      "Epoch 346/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0560 - acc: 0.6000 - val_loss: 1.3346 - val_acc: 0.5550\n",
      "Epoch 347/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0623 - acc: 0.5750 - val_loss: 1.3567 - val_acc: 0.5000\n",
      "Epoch 348/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0961 - acc: 0.5550 - val_loss: 1.3119 - val_acc: 0.5700\n",
      "Epoch 349/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0968 - acc: 0.5350 - val_loss: 1.3262 - val_acc: 0.5400\n",
      "Epoch 350/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9936 - acc: 0.5900 - val_loss: 1.5226 - val_acc: 0.5050\n",
      "Epoch 351/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1787 - acc: 0.5400 - val_loss: 1.3758 - val_acc: 0.5250\n",
      "Epoch 352/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0652 - acc: 0.5700 - val_loss: 1.3775 - val_acc: 0.5050\n",
      "Epoch 353/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9990 - acc: 0.6050 - val_loss: 1.3264 - val_acc: 0.5000\n",
      "Epoch 354/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1279 - acc: 0.5750 - val_loss: 1.2840 - val_acc: 0.5550\n",
      "Epoch 355/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0528 - acc: 0.5900 - val_loss: 1.2544 - val_acc: 0.5650\n",
      "Epoch 356/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0834 - acc: 0.6000 - val_loss: 1.2411 - val_acc: 0.6000\n",
      "Epoch 357/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0384 - acc: 0.5850 - val_loss: 1.2152 - val_acc: 0.6200\n",
      "Epoch 358/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0791 - acc: 0.5800 - val_loss: 1.3200 - val_acc: 0.5100\n",
      "Epoch 359/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9296 - acc: 0.6400 - val_loss: 1.3766 - val_acc: 0.5350\n",
      "Epoch 360/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0564 - acc: 0.5750 - val_loss: 1.4030 - val_acc: 0.5300\n",
      "Epoch 361/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9467 - acc: 0.6000 - val_loss: 1.4567 - val_acc: 0.5100\n",
      "Epoch 362/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0453 - acc: 0.5950 - val_loss: 1.4331 - val_acc: 0.5550\n",
      "Epoch 363/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0864 - acc: 0.5950 - val_loss: 1.4458 - val_acc: 0.5100\n",
      "Epoch 364/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1098 - acc: 0.5700 - val_loss: 1.4699 - val_acc: 0.5000\n",
      "Epoch 365/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0229 - acc: 0.5950 - val_loss: 1.3030 - val_acc: 0.5600\n",
      "Epoch 366/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0817 - acc: 0.5900 - val_loss: 1.4421 - val_acc: 0.5100\n",
      "Epoch 367/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0658 - acc: 0.6000 - val_loss: 1.4029 - val_acc: 0.5500\n",
      "Epoch 368/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2036 - acc: 0.5300 - val_loss: 1.3823 - val_acc: 0.5900\n",
      "Epoch 369/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1031 - acc: 0.5850 - val_loss: 1.4218 - val_acc: 0.5150\n",
      "Epoch 370/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0303 - acc: 0.5850 - val_loss: 1.4342 - val_acc: 0.5450\n",
      "Epoch 371/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1141 - acc: 0.5650 - val_loss: 1.3997 - val_acc: 0.5150\n",
      "Epoch 372/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0394 - acc: 0.6150 - val_loss: 1.3079 - val_acc: 0.5800\n",
      "Epoch 373/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0928 - acc: 0.5600 - val_loss: 1.3433 - val_acc: 0.5800\n",
      "Epoch 374/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1389 - acc: 0.5550 - val_loss: 1.4384 - val_acc: 0.5650\n",
      "Epoch 375/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0981 - acc: 0.5600 - val_loss: 1.4393 - val_acc: 0.5600\n",
      "Epoch 376/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0860 - acc: 0.5600 - val_loss: 1.4324 - val_acc: 0.5300\n",
      "Epoch 377/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1651 - acc: 0.5400 - val_loss: 1.5133 - val_acc: 0.5100\n",
      "Epoch 378/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1000 - acc: 0.5750 - val_loss: 1.4930 - val_acc: 0.5050\n",
      "Epoch 379/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0554 - acc: 0.6000 - val_loss: 1.4479 - val_acc: 0.5200\n",
      "Epoch 380/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2017 - acc: 0.4550 - val_loss: 1.4121 - val_acc: 0.5200\n",
      "Epoch 381/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1890 - acc: 0.5300 - val_loss: 1.3499 - val_acc: 0.5100\n",
      "Epoch 382/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0982 - acc: 0.5650 - val_loss: 1.4822 - val_acc: 0.5000\n",
      "Epoch 383/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0180 - acc: 0.5950 - val_loss: 1.3931 - val_acc: 0.5000\n",
      "Epoch 384/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0561 - acc: 0.5650 - val_loss: 1.3802 - val_acc: 0.4800\n",
      "Epoch 385/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1666 - acc: 0.5450 - val_loss: 1.3324 - val_acc: 0.5000\n",
      "Epoch 386/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.3104 - acc: 0.5150 - val_loss: 1.2818 - val_acc: 0.5300\n",
      "Epoch 387/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0588 - acc: 0.6000 - val_loss: 1.2709 - val_acc: 0.5500\n",
      "Epoch 388/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0997 - acc: 0.5950 - val_loss: 1.3891 - val_acc: 0.5050\n",
      "Epoch 389/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9948 - acc: 0.5850 - val_loss: 1.2637 - val_acc: 0.5400\n",
      "Epoch 390/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2111 - acc: 0.5150 - val_loss: 1.3715 - val_acc: 0.5300\n",
      "Epoch 391/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1146 - acc: 0.5600 - val_loss: 1.1953 - val_acc: 0.6100\n",
      "Epoch 392/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0413 - acc: 0.5650 - val_loss: 1.2963 - val_acc: 0.5400\n",
      "Epoch 393/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1067 - acc: 0.5300 - val_loss: 1.3906 - val_acc: 0.5800\n",
      "Epoch 394/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9845 - acc: 0.6050 - val_loss: 1.3143 - val_acc: 0.5450\n",
      "Epoch 395/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1620 - acc: 0.5400 - val_loss: 1.3324 - val_acc: 0.5050\n",
      "Epoch 396/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9908 - acc: 0.6200 - val_loss: 1.3120 - val_acc: 0.5150\n",
      "Epoch 397/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9070 - acc: 0.6000 - val_loss: 1.3415 - val_acc: 0.5200\n",
      "Epoch 398/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9969 - acc: 0.5950 - val_loss: 1.3432 - val_acc: 0.5650\n",
      "Epoch 399/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0412 - acc: 0.5650 - val_loss: 1.4240 - val_acc: 0.4600\n",
      "Epoch 400/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9300 - acc: 0.6350 - val_loss: 1.3120 - val_acc: 0.4950\n",
      "Epoch 401/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0425 - acc: 0.5750 - val_loss: 1.4200 - val_acc: 0.5050\n",
      "Epoch 402/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0733 - acc: 0.5800 - val_loss: 1.2751 - val_acc: 0.6050\n",
      "Epoch 403/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1244 - acc: 0.5550 - val_loss: 2.4606 - val_acc: 0.3700\n",
      "Epoch 404/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0605 - acc: 0.5700 - val_loss: 1.4786 - val_acc: 0.4750\n",
      "Epoch 405/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0450 - acc: 0.5950 - val_loss: 1.6141 - val_acc: 0.4900\n",
      "Epoch 406/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9795 - acc: 0.5900 - val_loss: 1.4591 - val_acc: 0.5200\n",
      "Epoch 407/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9663 - acc: 0.6350 - val_loss: 1.3017 - val_acc: 0.5050\n",
      "Epoch 408/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0626 - acc: 0.5900 - val_loss: 1.4294 - val_acc: 0.4300\n",
      "Epoch 409/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9292 - acc: 0.5900 - val_loss: 1.3362 - val_acc: 0.5100\n",
      "Epoch 410/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0309 - acc: 0.6050 - val_loss: 1.3090 - val_acc: 0.5150\n",
      "Epoch 411/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0912 - acc: 0.6100 - val_loss: 1.3433 - val_acc: 0.5200\n",
      "Epoch 412/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0210 - acc: 0.5700 - val_loss: 1.5281 - val_acc: 0.5300\n",
      "Epoch 413/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1153 - acc: 0.5600 - val_loss: 1.3433 - val_acc: 0.5600\n",
      "Epoch 414/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0394 - acc: 0.5900 - val_loss: 1.2858 - val_acc: 0.5350\n",
      "Epoch 415/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8718 - acc: 0.6350 - val_loss: 1.4527 - val_acc: 0.5050\n",
      "Epoch 416/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0134 - acc: 0.5850 - val_loss: 1.2053 - val_acc: 0.5700\n",
      "Epoch 417/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0581 - acc: 0.5750 - val_loss: 1.3149 - val_acc: 0.5200\n",
      "Epoch 418/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2447 - acc: 0.5700 - val_loss: 1.2426 - val_acc: 0.5700\n",
      "Epoch 419/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0236 - acc: 0.5950 - val_loss: 1.2754 - val_acc: 0.5400\n",
      "Epoch 420/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1112 - acc: 0.5400 - val_loss: 1.3012 - val_acc: 0.5150\n",
      "Epoch 421/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9853 - acc: 0.5800 - val_loss: 1.4811 - val_acc: 0.4950\n",
      "Epoch 422/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9786 - acc: 0.5950 - val_loss: 1.3039 - val_acc: 0.5150\n",
      "Epoch 423/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0919 - acc: 0.5650 - val_loss: 1.5099 - val_acc: 0.5050\n",
      "Epoch 424/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0210 - acc: 0.5600 - val_loss: 1.2630 - val_acc: 0.6000\n",
      "Epoch 425/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9136 - acc: 0.6050 - val_loss: 1.3779 - val_acc: 0.5300\n",
      "Epoch 426/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1006 - acc: 0.6000 - val_loss: 1.3511 - val_acc: 0.4900\n",
      "Epoch 427/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9476 - acc: 0.6250 - val_loss: 1.3113 - val_acc: 0.5100\n",
      "Epoch 428/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9704 - acc: 0.6200 - val_loss: 1.2286 - val_acc: 0.5700\n",
      "Epoch 429/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0138 - acc: 0.6200 - val_loss: 1.2278 - val_acc: 0.5500\n",
      "Epoch 430/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0730 - acc: 0.5750 - val_loss: 1.3637 - val_acc: 0.5250\n",
      "Epoch 431/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9665 - acc: 0.6200 - val_loss: 1.2570 - val_acc: 0.5400\n",
      "Epoch 432/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9803 - acc: 0.6100 - val_loss: 1.3187 - val_acc: 0.5400\n",
      "Epoch 433/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9640 - acc: 0.5850 - val_loss: 1.3308 - val_acc: 0.4800\n",
      "Epoch 434/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9684 - acc: 0.6250 - val_loss: 1.2854 - val_acc: 0.5250\n",
      "Epoch 435/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9587 - acc: 0.5950 - val_loss: 1.2539 - val_acc: 0.5350\n",
      "Epoch 436/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0330 - acc: 0.5800 - val_loss: 1.4743 - val_acc: 0.4950\n",
      "Epoch 437/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1165 - acc: 0.5400 - val_loss: 1.4249 - val_acc: 0.5100\n",
      "Epoch 438/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9605 - acc: 0.6200 - val_loss: 1.3823 - val_acc: 0.4900\n",
      "Epoch 439/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0045 - acc: 0.6200 - val_loss: 1.3333 - val_acc: 0.5100\n",
      "Epoch 440/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1868 - acc: 0.5250 - val_loss: 1.4008 - val_acc: 0.5550\n",
      "Epoch 441/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0995 - acc: 0.5750 - val_loss: 1.3374 - val_acc: 0.5200\n",
      "Epoch 442/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0742 - acc: 0.5750 - val_loss: 1.3652 - val_acc: 0.4950\n",
      "Epoch 443/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0025 - acc: 0.5700 - val_loss: 1.4974 - val_acc: 0.5300\n",
      "Epoch 444/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0984 - acc: 0.5650 - val_loss: 1.3880 - val_acc: 0.5200\n",
      "Epoch 445/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0387 - acc: 0.5850 - val_loss: 1.4393 - val_acc: 0.5400\n",
      "Epoch 446/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0145 - acc: 0.5850 - val_loss: 1.2167 - val_acc: 0.5900\n",
      "Epoch 447/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9713 - acc: 0.6000 - val_loss: 1.2829 - val_acc: 0.5450\n",
      "Epoch 448/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0346 - acc: 0.6050 - val_loss: 1.5592 - val_acc: 0.4850\n",
      "Epoch 449/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9855 - acc: 0.6150 - val_loss: 1.3335 - val_acc: 0.4800\n",
      "Epoch 450/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0717 - acc: 0.5500 - val_loss: 1.3385 - val_acc: 0.5500\n",
      "Epoch 451/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0143 - acc: 0.6000 - val_loss: 1.3459 - val_acc: 0.5250\n",
      "Epoch 452/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1615 - acc: 0.5400 - val_loss: 1.4395 - val_acc: 0.5450\n",
      "Epoch 453/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0464 - acc: 0.5950 - val_loss: 1.3679 - val_acc: 0.5300\n",
      "Epoch 454/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9971 - acc: 0.6000 - val_loss: 1.3273 - val_acc: 0.5400\n",
      "Epoch 455/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1744 - acc: 0.5900 - val_loss: 1.5856 - val_acc: 0.4950\n",
      "Epoch 456/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9827 - acc: 0.6000 - val_loss: 1.3635 - val_acc: 0.4800\n",
      "Epoch 457/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0332 - acc: 0.6050 - val_loss: 1.2913 - val_acc: 0.5650\n",
      "Epoch 458/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0867 - acc: 0.5550 - val_loss: 1.3492 - val_acc: 0.5000\n",
      "Epoch 459/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9973 - acc: 0.5850 - val_loss: 1.3609 - val_acc: 0.5700\n",
      "Epoch 460/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1567 - acc: 0.5550 - val_loss: 1.4181 - val_acc: 0.4950\n",
      "Epoch 461/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9987 - acc: 0.5600 - val_loss: 1.6400 - val_acc: 0.4850\n",
      "Epoch 462/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0547 - acc: 0.5450 - val_loss: 1.3468 - val_acc: 0.5650\n",
      "Epoch 463/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9335 - acc: 0.6150 - val_loss: 1.2152 - val_acc: 0.6250\n",
      "Epoch 464/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9367 - acc: 0.6050 - val_loss: 1.3779 - val_acc: 0.5250\n",
      "Epoch 465/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2306 - acc: 0.5300 - val_loss: 1.6847 - val_acc: 0.5100\n",
      "Epoch 466/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1758 - acc: 0.5550 - val_loss: 1.4050 - val_acc: 0.5200\n",
      "Epoch 467/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1174 - acc: 0.5350 - val_loss: 1.2951 - val_acc: 0.5250\n",
      "Epoch 468/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9251 - acc: 0.6400 - val_loss: 1.5625 - val_acc: 0.5250\n",
      "Epoch 469/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9811 - acc: 0.5950 - val_loss: 1.4621 - val_acc: 0.4800\n",
      "Epoch 470/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9866 - acc: 0.5950 - val_loss: 1.3641 - val_acc: 0.4900\n",
      "Epoch 471/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0216 - acc: 0.6150 - val_loss: 1.1931 - val_acc: 0.5300\n",
      "Epoch 472/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9561 - acc: 0.5750 - val_loss: 1.2729 - val_acc: 0.4850\n",
      "Epoch 473/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0596 - acc: 0.5900 - val_loss: 1.2227 - val_acc: 0.5600\n",
      "Epoch 474/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0963 - acc: 0.5500 - val_loss: 1.3961 - val_acc: 0.4750\n",
      "Epoch 475/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0003 - acc: 0.6100 - val_loss: 1.2934 - val_acc: 0.5100\n",
      "Epoch 476/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9186 - acc: 0.6600 - val_loss: 1.2714 - val_acc: 0.5700\n",
      "Epoch 477/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0973 - acc: 0.5700 - val_loss: 1.3683 - val_acc: 0.5250\n",
      "Epoch 478/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0362 - acc: 0.6000 - val_loss: 1.2786 - val_acc: 0.5450\n",
      "Epoch 479/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0784 - acc: 0.5850 - val_loss: 1.3826 - val_acc: 0.4800\n",
      "Epoch 480/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9829 - acc: 0.5950 - val_loss: 1.4577 - val_acc: 0.5400\n",
      "Epoch 481/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1630 - acc: 0.5850 - val_loss: 1.3061 - val_acc: 0.5100\n",
      "Epoch 482/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0550 - acc: 0.5850 - val_loss: 1.2346 - val_acc: 0.5300\n",
      "Epoch 483/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0651 - acc: 0.5700 - val_loss: 1.2725 - val_acc: 0.5450\n",
      "Epoch 484/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0728 - acc: 0.5900 - val_loss: 1.4297 - val_acc: 0.5000\n",
      "Epoch 485/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9969 - acc: 0.6300 - val_loss: 1.3010 - val_acc: 0.5700\n",
      "Epoch 486/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9316 - acc: 0.6150 - val_loss: 1.3342 - val_acc: 0.5900\n",
      "Epoch 487/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9500 - acc: 0.6250 - val_loss: 1.4041 - val_acc: 0.5650\n",
      "Epoch 488/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0544 - acc: 0.6300 - val_loss: 1.1878 - val_acc: 0.5700\n",
      "Epoch 489/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9153 - acc: 0.6450 - val_loss: 1.3476 - val_acc: 0.5500\n",
      "Epoch 490/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9652 - acc: 0.6200 - val_loss: 1.2397 - val_acc: 0.5550\n",
      "Epoch 491/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9767 - acc: 0.6000 - val_loss: 1.3113 - val_acc: 0.5700\n",
      "Epoch 492/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0460 - acc: 0.5950 - val_loss: 1.3514 - val_acc: 0.5700\n",
      "Epoch 493/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1251 - acc: 0.6050 - val_loss: 1.4541 - val_acc: 0.5550\n",
      "Epoch 494/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0482 - acc: 0.6050 - val_loss: 1.3008 - val_acc: 0.5600\n",
      "Epoch 495/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9432 - acc: 0.6350 - val_loss: 1.3027 - val_acc: 0.5350\n",
      "Epoch 496/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9258 - acc: 0.6500 - val_loss: 1.3225 - val_acc: 0.5200\n",
      "Epoch 497/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9066 - acc: 0.6400 - val_loss: 1.3177 - val_acc: 0.5350\n",
      "Epoch 498/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1124 - acc: 0.5550 - val_loss: 1.4493 - val_acc: 0.5100\n",
      "Epoch 499/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0519 - acc: 0.5650 - val_loss: 1.2278 - val_acc: 0.5750\n",
      "Epoch 500/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9649 - acc: 0.5850 - val_loss: 1.3515 - val_acc: 0.5450\n",
      "Epoch 501/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8947 - acc: 0.6400 - val_loss: 1.3591 - val_acc: 0.5400\n",
      "Epoch 502/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0430 - acc: 0.5750 - val_loss: 1.2605 - val_acc: 0.5750\n",
      "Epoch 503/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9089 - acc: 0.6500 - val_loss: 1.2707 - val_acc: 0.5400\n",
      "Epoch 504/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0257 - acc: 0.6150 - val_loss: 1.2050 - val_acc: 0.6350\n",
      "Epoch 505/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1168 - acc: 0.5450 - val_loss: 1.1998 - val_acc: 0.5250\n",
      "Epoch 506/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9803 - acc: 0.6100 - val_loss: 1.1874 - val_acc: 0.6350\n",
      "Epoch 507/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9907 - acc: 0.5750 - val_loss: 1.4344 - val_acc: 0.5800\n",
      "Epoch 508/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1633 - acc: 0.5300 - val_loss: 1.2861 - val_acc: 0.5650\n",
      "Epoch 509/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0181 - acc: 0.6200 - val_loss: 1.5041 - val_acc: 0.5500\n",
      "Epoch 510/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1354 - acc: 0.5450 - val_loss: 1.6011 - val_acc: 0.4950\n",
      "Epoch 511/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9580 - acc: 0.6250 - val_loss: 1.5211 - val_acc: 0.5100\n",
      "Epoch 512/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9813 - acc: 0.6500 - val_loss: 1.3352 - val_acc: 0.5400\n",
      "Epoch 513/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0802 - acc: 0.5700 - val_loss: 1.1867 - val_acc: 0.6100\n",
      "Epoch 514/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9800 - acc: 0.5650 - val_loss: 1.4189 - val_acc: 0.5050\n",
      "Epoch 515/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9095 - acc: 0.6550 - val_loss: 1.4768 - val_acc: 0.5100\n",
      "Epoch 516/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8311 - acc: 0.6300 - val_loss: 1.5163 - val_acc: 0.5200\n",
      "Epoch 517/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0139 - acc: 0.5600 - val_loss: 1.4156 - val_acc: 0.5500\n",
      "Epoch 518/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9944 - acc: 0.6300 - val_loss: 1.2340 - val_acc: 0.5850\n",
      "Epoch 519/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0041 - acc: 0.6250 - val_loss: 1.2900 - val_acc: 0.5650\n",
      "Epoch 520/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8652 - acc: 0.6650 - val_loss: 1.3143 - val_acc: 0.5600\n",
      "Epoch 521/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9771 - acc: 0.6200 - val_loss: 1.5029 - val_acc: 0.5300\n",
      "Epoch 522/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9914 - acc: 0.6000 - val_loss: 1.3443 - val_acc: 0.5750\n",
      "Epoch 523/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0665 - acc: 0.6200 - val_loss: 1.4871 - val_acc: 0.4700\n",
      "Epoch 524/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0830 - acc: 0.5900 - val_loss: 1.5179 - val_acc: 0.4750\n",
      "Epoch 525/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0492 - acc: 0.5500 - val_loss: 1.5897 - val_acc: 0.4350\n",
      "Epoch 526/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1067 - acc: 0.5900 - val_loss: 1.4828 - val_acc: 0.5250\n",
      "Epoch 527/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0192 - acc: 0.6000 - val_loss: 1.4482 - val_acc: 0.4800\n",
      "Epoch 528/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9236 - acc: 0.6100 - val_loss: 1.4356 - val_acc: 0.4800\n",
      "Epoch 529/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0452 - acc: 0.6000 - val_loss: 1.4133 - val_acc: 0.5550\n",
      "Epoch 530/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9962 - acc: 0.5800 - val_loss: 1.3337 - val_acc: 0.5000\n",
      "Epoch 531/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9219 - acc: 0.6400 - val_loss: 1.3266 - val_acc: 0.5150\n",
      "Epoch 532/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1036 - acc: 0.6000 - val_loss: 1.3080 - val_acc: 0.5050\n",
      "Epoch 533/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1063 - acc: 0.6050 - val_loss: 1.5324 - val_acc: 0.5000\n",
      "Epoch 534/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0020 - acc: 0.5850 - val_loss: 1.3588 - val_acc: 0.5500\n",
      "Epoch 535/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0925 - acc: 0.5750 - val_loss: 1.2773 - val_acc: 0.5600\n",
      "Epoch 536/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9811 - acc: 0.6200 - val_loss: 1.4869 - val_acc: 0.5000\n",
      "Epoch 537/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0392 - acc: 0.6250 - val_loss: 1.2533 - val_acc: 0.6200\n",
      "Epoch 538/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0259 - acc: 0.6100 - val_loss: 1.5364 - val_acc: 0.4800\n",
      "Epoch 539/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8782 - acc: 0.6200 - val_loss: 1.4698 - val_acc: 0.4950\n",
      "Epoch 540/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9276 - acc: 0.6500 - val_loss: 1.6083 - val_acc: 0.4600\n",
      "Epoch 541/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9914 - acc: 0.5800 - val_loss: 1.6101 - val_acc: 0.5000\n",
      "Epoch 542/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0420 - acc: 0.5800 - val_loss: 1.3919 - val_acc: 0.5400\n",
      "Epoch 543/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9899 - acc: 0.5600 - val_loss: 1.3938 - val_acc: 0.5250\n",
      "Epoch 544/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0781 - acc: 0.5750 - val_loss: 1.4174 - val_acc: 0.4800\n",
      "Epoch 545/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1669 - acc: 0.5200 - val_loss: 1.3449 - val_acc: 0.5600\n",
      "Epoch 546/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9303 - acc: 0.6400 - val_loss: 1.5631 - val_acc: 0.4850\n",
      "Epoch 547/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9317 - acc: 0.6250 - val_loss: 1.3550 - val_acc: 0.5150\n",
      "Epoch 548/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9071 - acc: 0.6500 - val_loss: 1.3660 - val_acc: 0.5000\n",
      "Epoch 549/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9837 - acc: 0.6250 - val_loss: 1.2833 - val_acc: 0.5600\n",
      "Epoch 550/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9920 - acc: 0.6150 - val_loss: 1.4432 - val_acc: 0.5000\n",
      "Epoch 551/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9285 - acc: 0.6300 - val_loss: 1.5368 - val_acc: 0.4900\n",
      "Epoch 552/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9281 - acc: 0.6450 - val_loss: 1.5057 - val_acc: 0.5200\n",
      "Epoch 553/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0464 - acc: 0.5700 - val_loss: 1.3762 - val_acc: 0.5750\n",
      "Epoch 554/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0965 - acc: 0.5950 - val_loss: 1.6510 - val_acc: 0.4900\n",
      "Epoch 555/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9911 - acc: 0.6200 - val_loss: 1.3461 - val_acc: 0.5500\n",
      "Epoch 556/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0024 - acc: 0.6200 - val_loss: 1.4605 - val_acc: 0.5450\n",
      "Epoch 557/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0020 - acc: 0.6500 - val_loss: 1.3911 - val_acc: 0.5400\n",
      "Epoch 558/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9388 - acc: 0.6450 - val_loss: 1.5377 - val_acc: 0.5200\n",
      "Epoch 559/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0325 - acc: 0.6100 - val_loss: 1.5795 - val_acc: 0.4900\n",
      "Epoch 560/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0401 - acc: 0.5600 - val_loss: 1.3707 - val_acc: 0.5650\n",
      "Epoch 561/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9578 - acc: 0.6650 - val_loss: 1.3318 - val_acc: 0.5750\n",
      "Epoch 562/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0015 - acc: 0.5900 - val_loss: 1.4296 - val_acc: 0.5350\n",
      "Epoch 563/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9667 - acc: 0.6050 - val_loss: 1.3709 - val_acc: 0.5600\n",
      "Epoch 564/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0540 - acc: 0.5700 - val_loss: 1.4640 - val_acc: 0.4950\n",
      "Epoch 565/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9465 - acc: 0.6350 - val_loss: 1.5724 - val_acc: 0.4850\n",
      "Epoch 566/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9731 - acc: 0.6350 - val_loss: 1.5276 - val_acc: 0.5000\n",
      "Epoch 567/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0198 - acc: 0.6050 - val_loss: 1.5430 - val_acc: 0.5400\n",
      "Epoch 568/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0771 - acc: 0.5750 - val_loss: 1.6570 - val_acc: 0.4750\n",
      "Epoch 569/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9548 - acc: 0.6200 - val_loss: 1.6554 - val_acc: 0.5050\n",
      "Epoch 570/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8687 - acc: 0.6950 - val_loss: 1.6168 - val_acc: 0.5050\n",
      "Epoch 571/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9728 - acc: 0.6150 - val_loss: 1.5423 - val_acc: 0.5450\n",
      "Epoch 572/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9067 - acc: 0.6500 - val_loss: 1.5103 - val_acc: 0.5350\n",
      "Epoch 573/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9022 - acc: 0.6500 - val_loss: 1.5330 - val_acc: 0.5350\n",
      "Epoch 574/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9725 - acc: 0.6200 - val_loss: 1.5660 - val_acc: 0.4850\n",
      "Epoch 575/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1468 - acc: 0.5350 - val_loss: 1.4634 - val_acc: 0.4950\n",
      "Epoch 576/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9486 - acc: 0.5950 - val_loss: 1.5583 - val_acc: 0.5000\n",
      "Epoch 577/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9891 - acc: 0.6050 - val_loss: 1.5893 - val_acc: 0.5050\n",
      "Epoch 578/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9934 - acc: 0.5950 - val_loss: 1.4725 - val_acc: 0.4850\n",
      "Epoch 579/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1685 - acc: 0.5450 - val_loss: 1.7596 - val_acc: 0.4950\n",
      "Epoch 580/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0735 - acc: 0.5400 - val_loss: 1.5423 - val_acc: 0.5050\n",
      "Epoch 581/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0229 - acc: 0.5700 - val_loss: 1.3629 - val_acc: 0.5100\n",
      "Epoch 582/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0858 - acc: 0.5750 - val_loss: 1.4778 - val_acc: 0.4950\n",
      "Epoch 583/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9223 - acc: 0.6550 - val_loss: 1.1772 - val_acc: 0.6000\n",
      "Epoch 584/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0678 - acc: 0.5750 - val_loss: 1.4503 - val_acc: 0.4450\n",
      "Epoch 585/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9824 - acc: 0.6300 - val_loss: 1.4552 - val_acc: 0.5050\n",
      "Epoch 586/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8376 - acc: 0.6600 - val_loss: 1.5133 - val_acc: 0.5000\n",
      "Epoch 587/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9063 - acc: 0.6500 - val_loss: 1.7973 - val_acc: 0.4900\n",
      "Epoch 588/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9643 - acc: 0.6300 - val_loss: 1.7821 - val_acc: 0.4750\n",
      "Epoch 589/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9754 - acc: 0.6050 - val_loss: 1.5532 - val_acc: 0.4950\n",
      "Epoch 590/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0239 - acc: 0.5900 - val_loss: 1.4758 - val_acc: 0.5150\n",
      "Epoch 591/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0736 - acc: 0.5750 - val_loss: 1.3968 - val_acc: 0.5750\n",
      "Epoch 592/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9178 - acc: 0.6350 - val_loss: 1.4265 - val_acc: 0.5450\n",
      "Epoch 593/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8786 - acc: 0.6550 - val_loss: 1.6323 - val_acc: 0.5350\n",
      "Epoch 594/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9670 - acc: 0.6450 - val_loss: 1.4977 - val_acc: 0.5300\n",
      "Epoch 595/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9138 - acc: 0.6050 - val_loss: 1.4525 - val_acc: 0.5400\n",
      "Epoch 596/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9486 - acc: 0.6200 - val_loss: 1.6550 - val_acc: 0.5050\n",
      "Epoch 597/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9532 - acc: 0.6100 - val_loss: 1.5544 - val_acc: 0.4800\n",
      "Epoch 598/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1281 - acc: 0.5750 - val_loss: 1.5739 - val_acc: 0.5150\n",
      "Epoch 599/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8856 - acc: 0.6700 - val_loss: 1.4590 - val_acc: 0.5400\n",
      "Epoch 600/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9995 - acc: 0.6200 - val_loss: 1.5356 - val_acc: 0.5300\n",
      "Epoch 601/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0379 - acc: 0.6150 - val_loss: 1.3929 - val_acc: 0.5350\n",
      "Epoch 602/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0810 - acc: 0.6000 - val_loss: 1.5159 - val_acc: 0.5400\n",
      "Epoch 603/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0163 - acc: 0.6000 - val_loss: 1.3333 - val_acc: 0.5550\n",
      "Epoch 604/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0944 - acc: 0.5700 - val_loss: 1.1459 - val_acc: 0.6550\n",
      "Epoch 605/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9662 - acc: 0.6000 - val_loss: 1.1882 - val_acc: 0.6300\n",
      "Epoch 606/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0891 - acc: 0.5800 - val_loss: 1.5701 - val_acc: 0.5250\n",
      "Epoch 607/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9994 - acc: 0.5750 - val_loss: 1.5280 - val_acc: 0.5350\n",
      "Epoch 608/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8546 - acc: 0.6700 - val_loss: 1.5130 - val_acc: 0.5050\n",
      "Epoch 609/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8710 - acc: 0.6450 - val_loss: 1.4821 - val_acc: 0.5300\n",
      "Epoch 610/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9388 - acc: 0.6050 - val_loss: 1.3876 - val_acc: 0.5300\n",
      "Epoch 611/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0515 - acc: 0.6150 - val_loss: 1.3390 - val_acc: 0.5050\n",
      "Epoch 612/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9505 - acc: 0.5850 - val_loss: 1.3774 - val_acc: 0.5250\n",
      "Epoch 613/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9349 - acc: 0.6200 - val_loss: 1.4172 - val_acc: 0.5200\n",
      "Epoch 614/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0216 - acc: 0.5900 - val_loss: 1.4189 - val_acc: 0.5000\n",
      "Epoch 615/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9983 - acc: 0.6300 - val_loss: 1.5399 - val_acc: 0.5100\n",
      "Epoch 616/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9812 - acc: 0.6050 - val_loss: 1.2595 - val_acc: 0.6000\n",
      "Epoch 617/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8897 - acc: 0.6400 - val_loss: 1.3257 - val_acc: 0.5950\n",
      "Epoch 618/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9959 - acc: 0.6300 - val_loss: 1.2502 - val_acc: 0.5850\n",
      "Epoch 619/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8900 - acc: 0.6650 - val_loss: 1.4580 - val_acc: 0.5650\n",
      "Epoch 620/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0099 - acc: 0.6300 - val_loss: 1.3572 - val_acc: 0.5750\n",
      "Epoch 621/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8580 - acc: 0.6700 - val_loss: 1.3473 - val_acc: 0.5450\n",
      "Epoch 622/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8958 - acc: 0.6300 - val_loss: 1.2825 - val_acc: 0.5550\n",
      "Epoch 623/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9535 - acc: 0.5900 - val_loss: 1.4629 - val_acc: 0.5050\n",
      "Epoch 624/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7940 - acc: 0.6500 - val_loss: 1.3426 - val_acc: 0.5650\n",
      "Epoch 625/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9844 - acc: 0.6200 - val_loss: 1.5993 - val_acc: 0.5000\n",
      "Epoch 626/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8788 - acc: 0.6400 - val_loss: 1.6555 - val_acc: 0.4450\n",
      "Epoch 627/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8753 - acc: 0.6150 - val_loss: 1.3576 - val_acc: 0.6400\n",
      "Epoch 628/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9998 - acc: 0.6100 - val_loss: 1.4094 - val_acc: 0.5500\n",
      "Epoch 629/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0789 - acc: 0.5500 - val_loss: 1.4257 - val_acc: 0.5150\n",
      "Epoch 630/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9482 - acc: 0.6250 - val_loss: 1.3716 - val_acc: 0.5600\n",
      "Epoch 631/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0021 - acc: 0.5900 - val_loss: 1.3613 - val_acc: 0.5500\n",
      "Epoch 632/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0102 - acc: 0.5950 - val_loss: 1.3154 - val_acc: 0.5400\n",
      "Epoch 633/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0296 - acc: 0.6150 - val_loss: 1.3618 - val_acc: 0.5600\n",
      "Epoch 634/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1136 - acc: 0.5750 - val_loss: 1.4310 - val_acc: 0.5950\n",
      "Epoch 635/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9449 - acc: 0.6000 - val_loss: 1.3944 - val_acc: 0.5300\n",
      "Epoch 636/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.2873 - acc: 0.5550 - val_loss: 1.3405 - val_acc: 0.6350\n",
      "Epoch 637/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9271 - acc: 0.6350 - val_loss: 1.4308 - val_acc: 0.5450\n",
      "Epoch 638/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0290 - acc: 0.6000 - val_loss: 1.4169 - val_acc: 0.5000\n",
      "Epoch 639/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9962 - acc: 0.5650 - val_loss: 1.4147 - val_acc: 0.5200\n",
      "Epoch 640/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8723 - acc: 0.6400 - val_loss: 1.4344 - val_acc: 0.5100\n",
      "Epoch 641/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9564 - acc: 0.5950 - val_loss: 1.3792 - val_acc: 0.5500\n",
      "Epoch 642/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9064 - acc: 0.6400 - val_loss: 1.5165 - val_acc: 0.5600\n",
      "Epoch 643/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8897 - acc: 0.6050 - val_loss: 1.3927 - val_acc: 0.5550\n",
      "Epoch 644/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9391 - acc: 0.6300 - val_loss: 1.4731 - val_acc: 0.5400\n",
      "Epoch 645/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9073 - acc: 0.6250 - val_loss: 1.4653 - val_acc: 0.5250\n",
      "Epoch 646/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9561 - acc: 0.6450 - val_loss: 1.4768 - val_acc: 0.5650\n",
      "Epoch 647/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9964 - acc: 0.6150 - val_loss: 1.3651 - val_acc: 0.5600\n",
      "Epoch 648/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8173 - acc: 0.6700 - val_loss: 1.2416 - val_acc: 0.5800\n",
      "Epoch 649/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0539 - acc: 0.5800 - val_loss: 1.2886 - val_acc: 0.5700\n",
      "Epoch 650/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9609 - acc: 0.5950 - val_loss: 1.3583 - val_acc: 0.5650\n",
      "Epoch 651/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9356 - acc: 0.6500 - val_loss: 1.3116 - val_acc: 0.5600\n",
      "Epoch 652/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9149 - acc: 0.6200 - val_loss: 1.2399 - val_acc: 0.5700\n",
      "Epoch 653/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8539 - acc: 0.6800 - val_loss: 1.1791 - val_acc: 0.6200\n",
      "Epoch 654/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9806 - acc: 0.6100 - val_loss: 1.3035 - val_acc: 0.5400\n",
      "Epoch 655/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9700 - acc: 0.6400 - val_loss: 1.3246 - val_acc: 0.5750\n",
      "Epoch 656/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9612 - acc: 0.6300 - val_loss: 1.3349 - val_acc: 0.5650\n",
      "Epoch 657/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0330 - acc: 0.5950 - val_loss: 1.2313 - val_acc: 0.6500\n",
      "Epoch 658/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0249 - acc: 0.6100 - val_loss: 1.2968 - val_acc: 0.5850\n",
      "Epoch 659/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0179 - acc: 0.5950 - val_loss: 1.2108 - val_acc: 0.6250\n",
      "Epoch 660/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9008 - acc: 0.6050 - val_loss: 1.3628 - val_acc: 0.5300\n",
      "Epoch 661/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0903 - acc: 0.5850 - val_loss: 1.2466 - val_acc: 0.6100\n",
      "Epoch 662/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8297 - acc: 0.6700 - val_loss: 1.1762 - val_acc: 0.6600\n",
      "Epoch 663/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9588 - acc: 0.6350 - val_loss: 1.3009 - val_acc: 0.5400\n",
      "Epoch 664/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9348 - acc: 0.6250 - val_loss: 1.3151 - val_acc: 0.5950\n",
      "Epoch 665/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.1293 - acc: 0.5550 - val_loss: 1.1842 - val_acc: 0.6400\n",
      "Epoch 666/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8753 - acc: 0.6450 - val_loss: 1.2660 - val_acc: 0.5800\n",
      "Epoch 667/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9363 - acc: 0.6350 - val_loss: 1.1929 - val_acc: 0.6350\n",
      "Epoch 668/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9756 - acc: 0.6000 - val_loss: 1.2878 - val_acc: 0.5750\n",
      "Epoch 669/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9747 - acc: 0.6200 - val_loss: 1.3793 - val_acc: 0.5400\n",
      "Epoch 670/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8451 - acc: 0.6800 - val_loss: 1.2861 - val_acc: 0.5350\n",
      "Epoch 671/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9548 - acc: 0.6300 - val_loss: 1.2829 - val_acc: 0.6100\n",
      "Epoch 672/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8548 - acc: 0.6400 - val_loss: 1.2552 - val_acc: 0.6400\n",
      "Epoch 673/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9786 - acc: 0.6100 - val_loss: 1.4050 - val_acc: 0.5700\n",
      "Epoch 674/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9562 - acc: 0.5950 - val_loss: 1.4856 - val_acc: 0.5250\n",
      "Epoch 675/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0074 - acc: 0.6150 - val_loss: 1.2930 - val_acc: 0.5550\n",
      "Epoch 676/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0029 - acc: 0.6150 - val_loss: 1.3093 - val_acc: 0.5800\n",
      "Epoch 677/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0276 - acc: 0.6100 - val_loss: 1.3020 - val_acc: 0.5700\n",
      "Epoch 678/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8084 - acc: 0.6850 - val_loss: 1.2711 - val_acc: 0.5650\n",
      "Epoch 679/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9581 - acc: 0.6250 - val_loss: 1.3409 - val_acc: 0.5550\n",
      "Epoch 680/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9176 - acc: 0.6450 - val_loss: 1.2591 - val_acc: 0.5600\n",
      "Epoch 681/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8772 - acc: 0.6600 - val_loss: 1.2287 - val_acc: 0.5900\n",
      "Epoch 682/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9599 - acc: 0.6400 - val_loss: 1.3950 - val_acc: 0.5350\n",
      "Epoch 683/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9309 - acc: 0.5700 - val_loss: 1.3989 - val_acc: 0.5700\n",
      "Epoch 684/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0050 - acc: 0.6150 - val_loss: 1.4335 - val_acc: 0.5700\n",
      "Epoch 685/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8446 - acc: 0.6350 - val_loss: 1.3792 - val_acc: 0.5700\n",
      "Epoch 686/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8380 - acc: 0.6750 - val_loss: 1.5589 - val_acc: 0.5600\n",
      "Epoch 687/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9041 - acc: 0.6700 - val_loss: 1.4781 - val_acc: 0.5950\n",
      "Epoch 688/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0207 - acc: 0.6000 - val_loss: 1.3275 - val_acc: 0.6000\n",
      "Epoch 689/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0127 - acc: 0.6400 - val_loss: 1.5151 - val_acc: 0.5650\n",
      "Epoch 690/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9920 - acc: 0.6350 - val_loss: 1.1943 - val_acc: 0.6950\n",
      "Epoch 691/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8488 - acc: 0.6550 - val_loss: 1.3614 - val_acc: 0.5700\n",
      "Epoch 692/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9805 - acc: 0.5900 - val_loss: 1.2723 - val_acc: 0.5700\n",
      "Epoch 693/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9259 - acc: 0.6300 - val_loss: 1.3204 - val_acc: 0.5850\n",
      "Epoch 694/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9632 - acc: 0.6050 - val_loss: 1.4419 - val_acc: 0.5700\n",
      "Epoch 695/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0206 - acc: 0.5850 - val_loss: 1.4831 - val_acc: 0.5750\n",
      "Epoch 696/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9914 - acc: 0.6200 - val_loss: 1.4236 - val_acc: 0.5850\n",
      "Epoch 697/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9704 - acc: 0.5900 - val_loss: 1.5103 - val_acc: 0.5550\n",
      "Epoch 698/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8923 - acc: 0.6400 - val_loss: 1.4813 - val_acc: 0.5400\n",
      "Epoch 699/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9272 - acc: 0.6350 - val_loss: 1.4637 - val_acc: 0.5850\n",
      "Epoch 700/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8507 - acc: 0.6500 - val_loss: 1.4875 - val_acc: 0.5450\n",
      "Epoch 701/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9013 - acc: 0.6300 - val_loss: 1.4076 - val_acc: 0.5750\n",
      "Epoch 702/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9918 - acc: 0.6050 - val_loss: 1.4258 - val_acc: 0.5500\n",
      "Epoch 703/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8967 - acc: 0.6650 - val_loss: 1.4605 - val_acc: 0.5600\n",
      "Epoch 704/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9439 - acc: 0.6200 - val_loss: 1.3172 - val_acc: 0.5450\n",
      "Epoch 705/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9570 - acc: 0.6500 - val_loss: 1.4741 - val_acc: 0.5000\n",
      "Epoch 706/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8483 - acc: 0.6650 - val_loss: 1.3562 - val_acc: 0.5600\n",
      "Epoch 707/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9654 - acc: 0.6250 - val_loss: 1.3017 - val_acc: 0.5700\n",
      "Epoch 708/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8916 - acc: 0.6500 - val_loss: 1.3028 - val_acc: 0.5400\n",
      "Epoch 709/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0874 - acc: 0.5700 - val_loss: 1.3655 - val_acc: 0.5500\n",
      "Epoch 710/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8598 - acc: 0.6850 - val_loss: 1.3941 - val_acc: 0.5500\n",
      "Epoch 711/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9499 - acc: 0.6500 - val_loss: 1.3844 - val_acc: 0.5950\n",
      "Epoch 712/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0478 - acc: 0.5450 - val_loss: 1.5258 - val_acc: 0.5600\n",
      "Epoch 713/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9788 - acc: 0.5850 - val_loss: 1.3742 - val_acc: 0.6500\n",
      "Epoch 714/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9735 - acc: 0.6050 - val_loss: 1.4398 - val_acc: 0.5900\n",
      "Epoch 715/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9220 - acc: 0.6250 - val_loss: 1.5396 - val_acc: 0.5400\n",
      "Epoch 716/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8902 - acc: 0.6400 - val_loss: 1.4163 - val_acc: 0.6300\n",
      "Epoch 717/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9552 - acc: 0.6300 - val_loss: 1.4864 - val_acc: 0.6050\n",
      "Epoch 718/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8880 - acc: 0.6450 - val_loss: 1.4379 - val_acc: 0.5850\n",
      "Epoch 719/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.0148 - acc: 0.5850 - val_loss: 1.3234 - val_acc: 0.6150\n",
      "Epoch 720/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7977 - acc: 0.6800 - val_loss: 1.1614 - val_acc: 0.7000\n",
      "Epoch 721/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2241 - acc: 0.5800 - val_loss: 1.5347 - val_acc: 0.5200\n",
      "Epoch 722/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8549 - acc: 0.6400 - val_loss: 1.4410 - val_acc: 0.5800\n",
      "Epoch 723/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9233 - acc: 0.6100 - val_loss: 1.2936 - val_acc: 0.5150\n",
      "Epoch 724/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9692 - acc: 0.5900 - val_loss: 1.2322 - val_acc: 0.5850\n",
      "Epoch 725/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8193 - acc: 0.6450 - val_loss: 1.2890 - val_acc: 0.5400\n",
      "Epoch 726/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0357 - acc: 0.6000 - val_loss: 1.3371 - val_acc: 0.5800\n",
      "Epoch 727/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8502 - acc: 0.6750 - val_loss: 1.2950 - val_acc: 0.6000\n",
      "Epoch 728/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8931 - acc: 0.6900 - val_loss: 1.2613 - val_acc: 0.5400\n",
      "Epoch 729/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9437 - acc: 0.6050 - val_loss: 1.4086 - val_acc: 0.5050\n",
      "Epoch 730/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0441 - acc: 0.5900 - val_loss: 1.5015 - val_acc: 0.5200\n",
      "Epoch 731/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9617 - acc: 0.6350 - val_loss: 1.4775 - val_acc: 0.5250\n",
      "Epoch 732/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9755 - acc: 0.6200 - val_loss: 1.3657 - val_acc: 0.4800\n",
      "Epoch 733/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9831 - acc: 0.5500 - val_loss: 1.3009 - val_acc: 0.5300\n",
      "Epoch 734/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8908 - acc: 0.6650 - val_loss: 1.2419 - val_acc: 0.6350\n",
      "Epoch 735/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8543 - acc: 0.6350 - val_loss: 1.3065 - val_acc: 0.6300\n",
      "Epoch 736/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0350 - acc: 0.5800 - val_loss: 1.3493 - val_acc: 0.5550\n",
      "Epoch 737/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0954 - acc: 0.5800 - val_loss: 1.4405 - val_acc: 0.5400\n",
      "Epoch 738/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8724 - acc: 0.6450 - val_loss: 1.4386 - val_acc: 0.5850\n",
      "Epoch 739/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9322 - acc: 0.6250 - val_loss: 1.5280 - val_acc: 0.5200\n",
      "Epoch 740/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8405 - acc: 0.6800 - val_loss: 1.3084 - val_acc: 0.5950\n",
      "Epoch 741/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8460 - acc: 0.6500 - val_loss: 1.1915 - val_acc: 0.5650\n",
      "Epoch 742/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9843 - acc: 0.5900 - val_loss: 1.2608 - val_acc: 0.5550\n",
      "Epoch 743/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9551 - acc: 0.6800 - val_loss: 1.2759 - val_acc: 0.5850\n",
      "Epoch 744/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8141 - acc: 0.6750 - val_loss: 1.2212 - val_acc: 0.5950\n",
      "Epoch 745/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8210 - acc: 0.7150 - val_loss: 1.3213 - val_acc: 0.5800\n",
      "Epoch 746/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9143 - acc: 0.6400 - val_loss: 1.6694 - val_acc: 0.5200\n",
      "Epoch 747/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7935 - acc: 0.6950 - val_loss: 1.4053 - val_acc: 0.5300\n",
      "Epoch 748/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9335 - acc: 0.6000 - val_loss: 1.3500 - val_acc: 0.5150\n",
      "Epoch 749/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9035 - acc: 0.6300 - val_loss: 1.5231 - val_acc: 0.5200\n",
      "Epoch 750/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8548 - acc: 0.6750 - val_loss: 1.4338 - val_acc: 0.5150\n",
      "Epoch 751/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0770 - acc: 0.6100 - val_loss: 1.5192 - val_acc: 0.5200\n",
      "Epoch 752/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9063 - acc: 0.6350 - val_loss: 1.1932 - val_acc: 0.5550\n",
      "Epoch 753/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8413 - acc: 0.6750 - val_loss: 1.2792 - val_acc: 0.5450\n",
      "Epoch 754/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9167 - acc: 0.6350 - val_loss: 1.3113 - val_acc: 0.5200\n",
      "Epoch 755/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8099 - acc: 0.6850 - val_loss: 1.3514 - val_acc: 0.5300\n",
      "Epoch 756/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8717 - acc: 0.6800 - val_loss: 1.3218 - val_acc: 0.5250\n",
      "Epoch 757/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8736 - acc: 0.6550 - val_loss: 1.3683 - val_acc: 0.5250\n",
      "Epoch 758/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9245 - acc: 0.6450 - val_loss: 1.2553 - val_acc: 0.5700\n",
      "Epoch 759/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9186 - acc: 0.6400 - val_loss: 1.4111 - val_acc: 0.5150\n",
      "Epoch 760/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9748 - acc: 0.6250 - val_loss: 1.4538 - val_acc: 0.5200\n",
      "Epoch 761/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0183 - acc: 0.6350 - val_loss: 1.3430 - val_acc: 0.5350\n",
      "Epoch 762/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7886 - acc: 0.6650 - val_loss: 1.3800 - val_acc: 0.5100\n",
      "Epoch 763/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7652 - acc: 0.6850 - val_loss: 1.3366 - val_acc: 0.5550\n",
      "Epoch 764/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9334 - acc: 0.6450 - val_loss: 1.3876 - val_acc: 0.5200\n",
      "Epoch 765/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7788 - acc: 0.6950 - val_loss: 1.2740 - val_acc: 0.5250\n",
      "Epoch 766/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8343 - acc: 0.6400 - val_loss: 1.3568 - val_acc: 0.5600\n",
      "Epoch 767/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8646 - acc: 0.6550 - val_loss: 1.5009 - val_acc: 0.5300\n",
      "Epoch 768/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8478 - acc: 0.6650 - val_loss: 1.3958 - val_acc: 0.5750\n",
      "Epoch 769/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9369 - acc: 0.6000 - val_loss: 1.3978 - val_acc: 0.5800\n",
      "Epoch 770/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9766 - acc: 0.6450 - val_loss: 1.4105 - val_acc: 0.4850\n",
      "Epoch 771/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8088 - acc: 0.6950 - val_loss: 1.3460 - val_acc: 0.5300\n",
      "Epoch 772/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9177 - acc: 0.6450 - val_loss: 1.3998 - val_acc: 0.5600\n",
      "Epoch 773/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9302 - acc: 0.6350 - val_loss: 1.3914 - val_acc: 0.5200\n",
      "Epoch 774/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9187 - acc: 0.6050 - val_loss: 1.5579 - val_acc: 0.5100\n",
      "Epoch 775/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9772 - acc: 0.6350 - val_loss: 1.3276 - val_acc: 0.5600\n",
      "Epoch 776/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0263 - acc: 0.6350 - val_loss: 1.3784 - val_acc: 0.5100\n",
      "Epoch 777/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8004 - acc: 0.6600 - val_loss: 1.3176 - val_acc: 0.6050\n",
      "Epoch 778/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9071 - acc: 0.6600 - val_loss: 1.3872 - val_acc: 0.5150\n",
      "Epoch 779/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0203 - acc: 0.5750 - val_loss: 1.2779 - val_acc: 0.5200\n",
      "Epoch 780/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9739 - acc: 0.6100 - val_loss: 1.4166 - val_acc: 0.5150\n",
      "Epoch 781/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8213 - acc: 0.6700 - val_loss: 1.2301 - val_acc: 0.5500\n",
      "Epoch 782/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8114 - acc: 0.6850 - val_loss: 1.2708 - val_acc: 0.5250\n",
      "Epoch 783/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8284 - acc: 0.6700 - val_loss: 1.3251 - val_acc: 0.4950\n",
      "Epoch 784/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9652 - acc: 0.6050 - val_loss: 1.3657 - val_acc: 0.5500\n",
      "Epoch 785/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9422 - acc: 0.5850 - val_loss: 1.3912 - val_acc: 0.5250\n",
      "Epoch 786/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8918 - acc: 0.6350 - val_loss: 1.5560 - val_acc: 0.5300\n",
      "Epoch 787/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8905 - acc: 0.6650 - val_loss: 1.3083 - val_acc: 0.5750\n",
      "Epoch 788/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8703 - acc: 0.6800 - val_loss: 1.2753 - val_acc: 0.5700\n",
      "Epoch 789/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7408 - acc: 0.7150 - val_loss: 1.1806 - val_acc: 0.6150\n",
      "Epoch 790/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8311 - acc: 0.6850 - val_loss: 1.2088 - val_acc: 0.5450\n",
      "Epoch 791/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8715 - acc: 0.6600 - val_loss: 1.2579 - val_acc: 0.4850\n",
      "Epoch 792/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8334 - acc: 0.6550 - val_loss: 1.3298 - val_acc: 0.5300\n",
      "Epoch 793/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7600 - acc: 0.6900 - val_loss: 1.2774 - val_acc: 0.5350\n",
      "Epoch 794/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0302 - acc: 0.6300 - val_loss: 1.2773 - val_acc: 0.5100\n",
      "Epoch 795/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8986 - acc: 0.6550 - val_loss: 1.2949 - val_acc: 0.5150\n",
      "Epoch 796/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9180 - acc: 0.6700 - val_loss: 1.2079 - val_acc: 0.4700\n",
      "Epoch 797/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8487 - acc: 0.6650 - val_loss: 1.2403 - val_acc: 0.5550\n",
      "Epoch 798/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7915 - acc: 0.6550 - val_loss: 1.1983 - val_acc: 0.5850\n",
      "Epoch 799/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8104 - acc: 0.7050 - val_loss: 1.2233 - val_acc: 0.5550\n",
      "Epoch 800/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8657 - acc: 0.6400 - val_loss: 1.1798 - val_acc: 0.5650\n",
      "Epoch 801/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8714 - acc: 0.6650 - val_loss: 1.3529 - val_acc: 0.5550\n",
      "Epoch 802/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7918 - acc: 0.6750 - val_loss: 1.1884 - val_acc: 0.5400\n",
      "Epoch 803/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9342 - acc: 0.6800 - val_loss: 1.1862 - val_acc: 0.6350\n",
      "Epoch 804/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8516 - acc: 0.6800 - val_loss: 1.2005 - val_acc: 0.6050\n",
      "Epoch 805/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9918 - acc: 0.6250 - val_loss: 1.2992 - val_acc: 0.5500\n",
      "Epoch 806/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8498 - acc: 0.6550 - val_loss: 1.1845 - val_acc: 0.5850\n",
      "Epoch 807/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7966 - acc: 0.6850 - val_loss: 1.2381 - val_acc: 0.5700\n",
      "Epoch 808/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8490 - acc: 0.6550 - val_loss: 1.2500 - val_acc: 0.5650\n",
      "Epoch 809/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8769 - acc: 0.6650 - val_loss: 1.2093 - val_acc: 0.5400\n",
      "Epoch 810/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9161 - acc: 0.6750 - val_loss: 1.3698 - val_acc: 0.5500\n",
      "Epoch 811/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7800 - acc: 0.6950 - val_loss: 1.3243 - val_acc: 0.6100\n",
      "Epoch 812/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9683 - acc: 0.6600 - val_loss: 1.2813 - val_acc: 0.5750\n",
      "Epoch 813/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7312 - acc: 0.7000 - val_loss: 1.3272 - val_acc: 0.5800\n",
      "Epoch 814/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9429 - acc: 0.6250 - val_loss: 1.3284 - val_acc: 0.5850\n",
      "Epoch 815/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8882 - acc: 0.6250 - val_loss: 1.3270 - val_acc: 0.6000\n",
      "Epoch 816/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9243 - acc: 0.6300 - val_loss: 1.3644 - val_acc: 0.5950\n",
      "Epoch 817/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9040 - acc: 0.6450 - val_loss: 1.1529 - val_acc: 0.6150\n",
      "Epoch 818/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9451 - acc: 0.6700 - val_loss: 1.1747 - val_acc: 0.5800\n",
      "Epoch 819/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8385 - acc: 0.6400 - val_loss: 1.2496 - val_acc: 0.6050\n",
      "Epoch 820/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9042 - acc: 0.6500 - val_loss: 1.1748 - val_acc: 0.5750\n",
      "Epoch 821/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7966 - acc: 0.6850 - val_loss: 1.2356 - val_acc: 0.5350\n",
      "Epoch 822/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9426 - acc: 0.6800 - val_loss: 1.3337 - val_acc: 0.5450\n",
      "Epoch 823/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6915 - acc: 0.7000 - val_loss: 1.2501 - val_acc: 0.5350\n",
      "Epoch 824/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8089 - acc: 0.6700 - val_loss: 1.2721 - val_acc: 0.5200\n",
      "Epoch 825/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7498 - acc: 0.6750 - val_loss: 1.2523 - val_acc: 0.5500\n",
      "Epoch 826/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7642 - acc: 0.6900 - val_loss: 1.2019 - val_acc: 0.5850\n",
      "Epoch 827/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9221 - acc: 0.6200 - val_loss: 1.2281 - val_acc: 0.5500\n",
      "Epoch 828/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8831 - acc: 0.6450 - val_loss: 1.4334 - val_acc: 0.5950\n",
      "Epoch 829/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8563 - acc: 0.6800 - val_loss: 1.1547 - val_acc: 0.6500\n",
      "Epoch 830/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7583 - acc: 0.7050 - val_loss: 1.0345 - val_acc: 0.6950\n",
      "Epoch 831/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7675 - acc: 0.6750 - val_loss: 1.2245 - val_acc: 0.5650\n",
      "Epoch 832/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7131 - acc: 0.7300 - val_loss: 1.2259 - val_acc: 0.6100\n",
      "Epoch 833/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7645 - acc: 0.6600 - val_loss: 1.1164 - val_acc: 0.6250\n",
      "Epoch 834/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7730 - acc: 0.7300 - val_loss: 1.1525 - val_acc: 0.5800\n",
      "Epoch 835/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8060 - acc: 0.6450 - val_loss: 1.2015 - val_acc: 0.5600\n",
      "Epoch 836/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7930 - acc: 0.7050 - val_loss: 1.0784 - val_acc: 0.6350\n",
      "Epoch 837/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8899 - acc: 0.6750 - val_loss: 1.1834 - val_acc: 0.5700\n",
      "Epoch 838/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9851 - acc: 0.6250 - val_loss: 1.2880 - val_acc: 0.4750\n",
      "Epoch 839/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0521 - acc: 0.5650 - val_loss: 1.1462 - val_acc: 0.5750\n",
      "Epoch 840/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8492 - acc: 0.6900 - val_loss: 1.2014 - val_acc: 0.5550\n",
      "Epoch 841/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8746 - acc: 0.6500 - val_loss: 1.1098 - val_acc: 0.6400\n",
      "Epoch 842/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7886 - acc: 0.6850 - val_loss: 1.1007 - val_acc: 0.6050\n",
      "Epoch 843/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8703 - acc: 0.6350 - val_loss: 1.1772 - val_acc: 0.5300\n",
      "Epoch 844/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9040 - acc: 0.6600 - val_loss: 1.1421 - val_acc: 0.5300\n",
      "Epoch 845/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9521 - acc: 0.6150 - val_loss: 1.1787 - val_acc: 0.5900\n",
      "Epoch 846/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9273 - acc: 0.6300 - val_loss: 1.4322 - val_acc: 0.5100\n",
      "Epoch 847/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7241 - acc: 0.7300 - val_loss: 1.2421 - val_acc: 0.5400\n",
      "Epoch 848/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6724 - acc: 0.7150 - val_loss: 1.1089 - val_acc: 0.5750\n",
      "Epoch 849/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8000 - acc: 0.6700 - val_loss: 1.3313 - val_acc: 0.5200\n",
      "Epoch 850/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7443 - acc: 0.7450 - val_loss: 1.2672 - val_acc: 0.5950\n",
      "Epoch 851/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8679 - acc: 0.6700 - val_loss: 1.1721 - val_acc: 0.5850\n",
      "Epoch 852/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7830 - acc: 0.6750 - val_loss: 1.1313 - val_acc: 0.6300\n",
      "Epoch 853/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7530 - acc: 0.6800 - val_loss: 1.2567 - val_acc: 0.5450\n",
      "Epoch 854/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7848 - acc: 0.6350 - val_loss: 1.2572 - val_acc: 0.5500\n",
      "Epoch 855/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8578 - acc: 0.6550 - val_loss: 1.2192 - val_acc: 0.5400\n",
      "Epoch 856/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7378 - acc: 0.7200 - val_loss: 1.1313 - val_acc: 0.6200\n",
      "Epoch 857/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8948 - acc: 0.6700 - val_loss: 1.3739 - val_acc: 0.5550\n",
      "Epoch 858/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7538 - acc: 0.7400 - val_loss: 1.3898 - val_acc: 0.5650\n",
      "Epoch 859/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7276 - acc: 0.7300 - val_loss: 1.5350 - val_acc: 0.5150\n",
      "Epoch 860/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9109 - acc: 0.6650 - val_loss: 1.5941 - val_acc: 0.4500\n",
      "Epoch 861/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8115 - acc: 0.7100 - val_loss: 1.3636 - val_acc: 0.5600\n",
      "Epoch 862/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8666 - acc: 0.6850 - val_loss: 1.4348 - val_acc: 0.5450\n",
      "Epoch 863/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8352 - acc: 0.6850 - val_loss: 1.3389 - val_acc: 0.5300\n",
      "Epoch 864/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7220 - acc: 0.7550 - val_loss: 1.4191 - val_acc: 0.5300\n",
      "Epoch 865/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9060 - acc: 0.6600 - val_loss: 1.4347 - val_acc: 0.5350\n",
      "Epoch 866/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8294 - acc: 0.6600 - val_loss: 1.2268 - val_acc: 0.5300\n",
      "Epoch 867/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7549 - acc: 0.7000 - val_loss: 1.1519 - val_acc: 0.6100\n",
      "Epoch 868/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8110 - acc: 0.6600 - val_loss: 1.2153 - val_acc: 0.6050\n",
      "Epoch 869/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7678 - acc: 0.6850 - val_loss: 1.2899 - val_acc: 0.5650\n",
      "Epoch 870/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9712 - acc: 0.6200 - val_loss: 1.3200 - val_acc: 0.5200\n",
      "Epoch 871/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.0378 - acc: 0.6200 - val_loss: 1.4272 - val_acc: 0.5150\n",
      "Epoch 872/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8589 - acc: 0.6500 - val_loss: 1.3581 - val_acc: 0.5650\n",
      "Epoch 873/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7910 - acc: 0.6650 - val_loss: 1.5048 - val_acc: 0.5550\n",
      "Epoch 874/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7551 - acc: 0.7050 - val_loss: 1.4139 - val_acc: 0.5600\n",
      "Epoch 875/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7996 - acc: 0.6600 - val_loss: 1.5167 - val_acc: 0.5250\n",
      "Epoch 876/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9650 - acc: 0.6450 - val_loss: 1.6291 - val_acc: 0.5200\n",
      "Epoch 877/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7397 - acc: 0.7050 - val_loss: 1.2766 - val_acc: 0.5600\n",
      "Epoch 878/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7325 - acc: 0.7250 - val_loss: 1.1802 - val_acc: 0.5650\n",
      "Epoch 879/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7482 - acc: 0.7050 - val_loss: 1.3083 - val_acc: 0.5650\n",
      "Epoch 880/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7902 - acc: 0.6750 - val_loss: 1.2153 - val_acc: 0.5850\n",
      "Epoch 881/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9538 - acc: 0.7050 - val_loss: 1.1609 - val_acc: 0.6200\n",
      "Epoch 882/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7097 - acc: 0.6850 - val_loss: 1.2280 - val_acc: 0.5900\n",
      "Epoch 883/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8398 - acc: 0.6400 - val_loss: 1.2522 - val_acc: 0.5800\n",
      "Epoch 884/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7528 - acc: 0.7250 - val_loss: 1.1139 - val_acc: 0.6500\n",
      "Epoch 885/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8861 - acc: 0.6650 - val_loss: 1.3732 - val_acc: 0.5850\n",
      "Epoch 886/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7841 - acc: 0.7100 - val_loss: 1.2754 - val_acc: 0.5700\n",
      "Epoch 887/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8495 - acc: 0.6500 - val_loss: 1.4695 - val_acc: 0.5050\n",
      "Epoch 888/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7956 - acc: 0.7200 - val_loss: 1.3479 - val_acc: 0.5400\n",
      "Epoch 889/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8523 - acc: 0.6400 - val_loss: 1.1718 - val_acc: 0.6200\n",
      "Epoch 890/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7831 - acc: 0.7050 - val_loss: 1.2378 - val_acc: 0.5550\n",
      "Epoch 891/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7194 - acc: 0.7150 - val_loss: 1.2008 - val_acc: 0.6050\n",
      "Epoch 892/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8386 - acc: 0.6750 - val_loss: 1.3038 - val_acc: 0.5550\n",
      "Epoch 893/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7734 - acc: 0.7000 - val_loss: 1.1506 - val_acc: 0.6000\n",
      "Epoch 894/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6661 - acc: 0.7400 - val_loss: 1.2283 - val_acc: 0.5750\n",
      "Epoch 895/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8901 - acc: 0.6900 - val_loss: 1.3539 - val_acc: 0.5350\n",
      "Epoch 896/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8424 - acc: 0.6600 - val_loss: 1.4383 - val_acc: 0.4850\n",
      "Epoch 897/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8499 - acc: 0.6750 - val_loss: 1.5501 - val_acc: 0.5000\n",
      "Epoch 898/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8398 - acc: 0.6600 - val_loss: 1.2949 - val_acc: 0.5500\n",
      "Epoch 899/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8387 - acc: 0.6850 - val_loss: 1.3887 - val_acc: 0.5500\n",
      "Epoch 900/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0816 - acc: 0.6350 - val_loss: 1.5304 - val_acc: 0.5150\n",
      "Epoch 901/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7735 - acc: 0.7100 - val_loss: 1.3116 - val_acc: 0.5000\n",
      "Epoch 902/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8358 - acc: 0.6750 - val_loss: 1.1734 - val_acc: 0.6300\n",
      "Epoch 903/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8829 - acc: 0.6600 - val_loss: 1.3490 - val_acc: 0.5100\n",
      "Epoch 904/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8095 - acc: 0.7150 - val_loss: 1.2630 - val_acc: 0.5400\n",
      "Epoch 905/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8795 - acc: 0.6650 - val_loss: 1.1958 - val_acc: 0.6100\n",
      "Epoch 906/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8428 - acc: 0.6950 - val_loss: 1.1385 - val_acc: 0.6000\n",
      "Epoch 907/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8017 - acc: 0.6900 - val_loss: 1.1175 - val_acc: 0.5900\n",
      "Epoch 908/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8480 - acc: 0.7050 - val_loss: 1.1612 - val_acc: 0.5700\n",
      "Epoch 909/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8847 - acc: 0.6600 - val_loss: 1.0395 - val_acc: 0.6250\n",
      "Epoch 910/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8368 - acc: 0.6500 - val_loss: 1.2786 - val_acc: 0.5250\n",
      "Epoch 911/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9377 - acc: 0.6600 - val_loss: 1.3494 - val_acc: 0.5050\n",
      "Epoch 912/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7742 - acc: 0.6900 - val_loss: 1.1691 - val_acc: 0.6300\n",
      "Epoch 913/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7824 - acc: 0.6950 - val_loss: 1.3575 - val_acc: 0.5600\n",
      "Epoch 914/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8109 - acc: 0.6700 - val_loss: 1.1477 - val_acc: 0.5950\n",
      "Epoch 915/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6484 - acc: 0.7400 - val_loss: 1.2614 - val_acc: 0.5850\n",
      "Epoch 916/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8994 - acc: 0.6500 - val_loss: 1.4533 - val_acc: 0.5250\n",
      "Epoch 917/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8489 - acc: 0.6950 - val_loss: 1.3245 - val_acc: 0.5050\n",
      "Epoch 918/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7581 - acc: 0.6750 - val_loss: 1.1613 - val_acc: 0.6000\n",
      "Epoch 919/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7718 - acc: 0.6850 - val_loss: 1.1207 - val_acc: 0.6550\n",
      "Epoch 920/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8857 - acc: 0.6550 - val_loss: 1.2039 - val_acc: 0.5550\n",
      "Epoch 921/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6973 - acc: 0.7300 - val_loss: 1.2066 - val_acc: 0.5700\n",
      "Epoch 922/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8624 - acc: 0.6800 - val_loss: 1.2547 - val_acc: 0.5700\n",
      "Epoch 923/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7376 - acc: 0.6850 - val_loss: 1.2726 - val_acc: 0.5550\n",
      "Epoch 924/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8483 - acc: 0.6600 - val_loss: 1.1504 - val_acc: 0.6200\n",
      "Epoch 925/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7631 - acc: 0.6950 - val_loss: 1.1443 - val_acc: 0.6400\n",
      "Epoch 926/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7793 - acc: 0.6950 - val_loss: 1.2168 - val_acc: 0.5850\n",
      "Epoch 927/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7842 - acc: 0.6850 - val_loss: 1.1920 - val_acc: 0.5950\n",
      "Epoch 928/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7194 - acc: 0.7250 - val_loss: 1.1113 - val_acc: 0.6250\n",
      "Epoch 929/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7883 - acc: 0.6950 - val_loss: 1.1738 - val_acc: 0.6050\n",
      "Epoch 930/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8052 - acc: 0.7100 - val_loss: 1.2450 - val_acc: 0.5400\n",
      "Epoch 931/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9352 - acc: 0.6700 - val_loss: 1.5885 - val_acc: 0.5050\n",
      "Epoch 932/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8551 - acc: 0.6450 - val_loss: 1.2109 - val_acc: 0.5900\n",
      "Epoch 933/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8220 - acc: 0.6850 - val_loss: 1.2832 - val_acc: 0.4650\n",
      "Epoch 934/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9052 - acc: 0.6750 - val_loss: 1.2424 - val_acc: 0.5450\n",
      "Epoch 935/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8267 - acc: 0.6800 - val_loss: 1.1034 - val_acc: 0.6450\n",
      "Epoch 936/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7177 - acc: 0.7250 - val_loss: 1.1803 - val_acc: 0.5700\n",
      "Epoch 937/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8699 - acc: 0.6350 - val_loss: 1.2428 - val_acc: 0.5600\n",
      "Epoch 938/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7657 - acc: 0.7050 - val_loss: 1.1651 - val_acc: 0.5550\n",
      "Epoch 939/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8681 - acc: 0.6550 - val_loss: 1.4957 - val_acc: 0.5950\n",
      "Epoch 940/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7143 - acc: 0.6950 - val_loss: 1.1762 - val_acc: 0.5650\n",
      "Epoch 941/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9060 - acc: 0.6500 - val_loss: 1.4992 - val_acc: 0.4500\n",
      "Epoch 942/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7683 - acc: 0.6650 - val_loss: 1.2610 - val_acc: 0.5700\n",
      "Epoch 943/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7040 - acc: 0.7150 - val_loss: 1.2806 - val_acc: 0.5450\n",
      "Epoch 944/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7768 - acc: 0.7050 - val_loss: 1.2999 - val_acc: 0.4950\n",
      "Epoch 945/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9111 - acc: 0.6650 - val_loss: 1.1681 - val_acc: 0.5500\n",
      "Epoch 946/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7806 - acc: 0.7000 - val_loss: 1.1998 - val_acc: 0.5800\n",
      "Epoch 947/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7704 - acc: 0.6900 - val_loss: 1.2023 - val_acc: 0.5800\n",
      "Epoch 948/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8150 - acc: 0.6600 - val_loss: 1.1834 - val_acc: 0.6500\n",
      "Epoch 949/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7402 - acc: 0.7150 - val_loss: 1.2571 - val_acc: 0.5650\n",
      "Epoch 950/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7956 - acc: 0.6700 - val_loss: 1.2205 - val_acc: 0.6050\n",
      "Epoch 951/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8218 - acc: 0.6850 - val_loss: 1.1926 - val_acc: 0.5650\n",
      "Epoch 952/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6997 - acc: 0.7200 - val_loss: 1.2162 - val_acc: 0.5400\n",
      "Epoch 953/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7889 - acc: 0.6900 - val_loss: 1.2092 - val_acc: 0.5800\n",
      "Epoch 954/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9994 - acc: 0.6450 - val_loss: 1.0659 - val_acc: 0.5500\n",
      "Epoch 955/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7590 - acc: 0.6900 - val_loss: 1.1726 - val_acc: 0.5350\n",
      "Epoch 956/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7743 - acc: 0.6900 - val_loss: 1.1496 - val_acc: 0.5950\n",
      "Epoch 957/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7396 - acc: 0.6950 - val_loss: 1.1102 - val_acc: 0.5950\n",
      "Epoch 958/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7644 - acc: 0.6950 - val_loss: 1.1167 - val_acc: 0.6050\n",
      "Epoch 959/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7310 - acc: 0.7050 - val_loss: 1.1500 - val_acc: 0.6100\n",
      "Epoch 960/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7862 - acc: 0.6950 - val_loss: 1.2824 - val_acc: 0.5700\n",
      "Epoch 961/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7477 - acc: 0.6900 - val_loss: 1.2524 - val_acc: 0.5400\n",
      "Epoch 962/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7570 - acc: 0.6900 - val_loss: 1.3088 - val_acc: 0.5150\n",
      "Epoch 963/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8115 - acc: 0.6750 - val_loss: 1.3722 - val_acc: 0.5800\n",
      "Epoch 964/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8100 - acc: 0.6600 - val_loss: 1.2380 - val_acc: 0.5650\n",
      "Epoch 965/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7242 - acc: 0.6900 - val_loss: 1.2758 - val_acc: 0.6050\n",
      "Epoch 966/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6446 - acc: 0.7400 - val_loss: 1.2046 - val_acc: 0.6150\n",
      "Epoch 967/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7802 - acc: 0.7150 - val_loss: 1.1826 - val_acc: 0.6150\n",
      "Epoch 968/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8610 - acc: 0.6850 - val_loss: 1.2446 - val_acc: 0.5500\n",
      "Epoch 969/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6829 - acc: 0.6900 - val_loss: 1.2128 - val_acc: 0.5900\n",
      "Epoch 970/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7157 - acc: 0.7350 - val_loss: 1.2373 - val_acc: 0.6200\n",
      "Epoch 971/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7494 - acc: 0.7050 - val_loss: 1.2889 - val_acc: 0.5000\n",
      "Epoch 972/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9060 - acc: 0.6300 - val_loss: 1.3464 - val_acc: 0.5250\n",
      "Epoch 973/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6247 - acc: 0.7550 - val_loss: 1.2365 - val_acc: 0.5950\n",
      "Epoch 974/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.7059 - acc: 0.6950 - val_loss: 1.2882 - val_acc: 0.5850\n",
      "Epoch 975/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8780 - acc: 0.6750 - val_loss: 1.1689 - val_acc: 0.5800\n",
      "Epoch 976/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7896 - acc: 0.6900 - val_loss: 1.0755 - val_acc: 0.6200\n",
      "Epoch 977/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7248 - acc: 0.6550 - val_loss: 1.2363 - val_acc: 0.6200\n",
      "Epoch 978/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.9407 - acc: 0.6450 - val_loss: 1.2113 - val_acc: 0.5200\n",
      "Epoch 979/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7687 - acc: 0.6850 - val_loss: 1.1874 - val_acc: 0.6150\n",
      "Epoch 980/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7591 - acc: 0.7000 - val_loss: 1.1250 - val_acc: 0.6000\n",
      "Epoch 981/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.8256 - acc: 0.7200 - val_loss: 1.3162 - val_acc: 0.5750\n",
      "Epoch 982/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7887 - acc: 0.7200 - val_loss: 1.1243 - val_acc: 0.5800\n",
      "Epoch 983/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.8130 - acc: 0.7000 - val_loss: 1.3466 - val_acc: 0.5650\n",
      "Epoch 984/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7698 - acc: 0.7000 - val_loss: 1.2226 - val_acc: 0.5750\n",
      "Epoch 985/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8430 - acc: 0.6900 - val_loss: 1.4373 - val_acc: 0.5350\n",
      "Epoch 986/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7262 - acc: 0.7150 - val_loss: 1.3307 - val_acc: 0.5500\n",
      "Epoch 987/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7181 - acc: 0.7100 - val_loss: 1.1731 - val_acc: 0.5800\n",
      "Epoch 988/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7405 - acc: 0.6850 - val_loss: 1.3136 - val_acc: 0.5500\n",
      "Epoch 989/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.8649 - acc: 0.6600 - val_loss: 1.4260 - val_acc: 0.5350\n",
      "Epoch 990/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9557 - acc: 0.6400 - val_loss: 1.2264 - val_acc: 0.6050\n",
      "Epoch 991/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6818 - acc: 0.7250 - val_loss: 1.2204 - val_acc: 0.5750\n",
      "Epoch 992/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.7718 - acc: 0.6950 - val_loss: 1.5521 - val_acc: 0.5750\n",
      "Epoch 993/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7190 - acc: 0.6700 - val_loss: 1.2085 - val_acc: 0.5650\n",
      "Epoch 994/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6864 - acc: 0.7200 - val_loss: 1.3914 - val_acc: 0.5700\n",
      "Epoch 995/1000\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.6850 - acc: 0.6950 - val_loss: 1.3290 - val_acc: 0.5300\n",
      "Epoch 996/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7515 - acc: 0.7150 - val_loss: 1.2828 - val_acc: 0.5800\n",
      "Epoch 997/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7523 - acc: 0.6950 - val_loss: 1.2230 - val_acc: 0.5600\n",
      "Epoch 998/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6279 - acc: 0.7350 - val_loss: 1.2054 - val_acc: 0.5800\n",
      "Epoch 999/1000\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.6605 - acc: 0.7150 - val_loss: 1.2051 - val_acc: 0.6300\n",
      "Epoch 1000/1000\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7789 - acc: 0.7150 - val_loss: 1.2086 - val_acc: 0.6150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30b2c9e358>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_model.fit(X_train, y_train, batch_size=5, epochs=1000, \n",
    "             verbose=1, validation_data=(X_test, y_test),\n",
    "              callbacks=[tf_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_model.save(\"models/id_exp_4.h5\")\n",
    "id_model.save_weights(\"weights/id_exp_4-w.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = id_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 9, 8, 9, 1, 2, 5, 2, 1, 3, 5, 8, 0, 9, 0, 0, 1, 0, 3, 5, 9, 5,\n",
       "       3, 3, 6, 1, 7, 3, 3, 5, 9, 8, 6, 3, 2, 8, 9, 5, 1, 2, 8, 0, 0, 1, 6,\n",
       "       8, 8, 8, 3, 9, 6, 3, 6, 1, 5, 6, 2, 8, 3, 2, 3, 7, 9, 5, 8, 3, 5, 8,\n",
       "       9, 8, 0, 7, 9, 0, 9, 5, 2, 7, 9, 9, 2, 1, 3, 8, 3, 8, 3, 5, 8, 3, 0,\n",
       "       0, 3, 3, 8, 9, 1, 8, 7, 0, 5, 8, 1, 5, 2, 9, 8, 8, 2, 9, 8, 1, 1, 8,\n",
       "       5, 5, 5, 3, 0, 8, 5, 0, 0, 8, 3, 7, 3, 5, 3, 5, 5, 9, 0, 8, 3, 9, 1,\n",
       "       9, 2, 6, 5, 3, 8, 8, 1, 1, 5, 5, 7, 8, 3, 8, 9, 7, 0, 7, 1, 5, 3, 3,\n",
       "       6, 8, 1, 8, 0, 1, 5, 8, 3, 6, 5, 1, 8, 0, 5, 8, 9, 8, 8, 5, 0, 3, 8,\n",
       "       5, 3, 3, 5, 5, 1, 6, 8, 0, 1, 3, 5, 9, 1, 8, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = np.argmax(pred, axis=1)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_y = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61499999999999999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 16,  0,  0,  0,  0,  0,  0,  4,  0],\n",
       "       [ 0,  0,  0,  0,  0, 20,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 20,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  3,  0, 13,  0,  0,  0,  0,  2,  2],\n",
       "       [ 0,  0,  0,  0,  0, 12,  0,  0,  8,  0],\n",
       "       [ 0,  0, 10,  0,  0,  0, 10,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  1,  0,  9,  9,  0],\n",
       "       [ 0,  4,  0,  0,  0,  0,  0,  0, 16,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 20]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f30b1f953c8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30b21c3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
